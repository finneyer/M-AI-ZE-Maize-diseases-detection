{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d11444d-4a37-4242-a2dd-64a83c721bf8",
   "metadata": {},
   "source": [
    "# Template for Model training with wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9e8f51-7c69-4526-a291-9aaa1633d950",
   "metadata": {},
   "source": [
    "This Template is used late for the trainging of the different models  \n",
    "Please preregister on the homepage and provide the necessary API Key in the .env file  \n",
    "Maybee using Sweeps could ease the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3735c01b-2345-4ee7-b452-22819b40ced6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in /opt/conda/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.12/site-packages (from dotenv) (1.1.0)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.12/site-packages (0.19.9)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.12/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.12/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (5.28.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (6.1.1)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.10.6)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.12/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.12/site-packages (from wandb) (1.3.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from wandb) (75.8.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.12/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2024.12.14)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (3.12.1)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.15.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (645.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.0/645.0 MB\u001b[0m \u001b[31m118.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m122.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "Downloading ml_dtypes-0.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m125.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m125.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (404 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, markdown-it-py, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.2.2 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 keras-3.9.2 libclang-18.1.1 markdown-3.8 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.15.0 rich-14.0.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.0.1 werkzeug-3.1.3 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install dotenv\n",
    "!pip install wandb\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a3cd17-1d51-4292-bc75-36d17d218d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WANDB_API_KEY: [69ca...]\n"
     ]
    }
   ],
   "source": [
    "# check the .env file \n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get and print the WANDB_API_KEY\n",
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "print(f\"WANDB_API_KEY: [{wandb_api_key[:4]}...]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bb748ca-dadd-46bb-9392-0e9ba6390de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 16:44:24.751603: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744389864.769561    4503 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744389864.775027    4503 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744389864.788587    4503 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744389864.788603    4503 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744389864.788605    4503 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744389864.788606    4503 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 16:44:24.793238: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "\n",
    "import keras\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7e8723-f9e3-428c-a0a8-7bfaca694305",
   "metadata": {},
   "source": [
    "## Init Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6886293-34c4-4c84-89a5-95bbbe0db55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"DSPRO2_MAIZE\"\n",
    "RUN_NR = 1\n",
    "\n",
    "\n",
    "# Start a run, tracking hyperparameters\n",
    "run = wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=PROJECT_NAME,\n",
    "\n",
    "    # Subname of this RUN\n",
    "    name = f\"Model_1_{RUN_NR}\",\n",
    "\n",
    "    # track hyperparameters and run metadata with wandb.config\n",
    "    config={\n",
    "        \"layer_1\": 512,\n",
    "        \"activation_hidden\": \"relu\",\n",
    "        \"dropout\": random.uniform(0.01, 0.80),\n",
    "        \"layer_2\": 10,\n",
    "        \"activation_output\": \"softmax\",\n",
    "        \"optimizer\": \"sgd\",\n",
    "        \"loss\": \"sparse_categorical_crossentropy\",\n",
    "        \"metric\": \"accuracy\",\n",
    "        \"epoch\": 8,\n",
    "        \"batch_size\": 256\n",
    "    }\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a469efb8-7f3b-4739-afaf-b55db04141af",
   "metadata": {},
   "source": [
    "## Experiment Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93d1f6c3-8db7-4902-b40c-bd6bad4b7a85",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wandb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# (optional) use wandb.config as your config\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mwandb\u001b[49m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpprint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pprint\n\u001b[1;32m      6\u001b[0m pprint(\u001b[38;5;28mdict\u001b[39m(config), indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wandb' is not defined"
     ]
    }
   ],
   "source": [
    "# (optional) use wandb.config as your config\n",
    "config = wandb.config\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(dict(config), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878676ea-aaaa-406c-a331-9920330a5390",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config.loss)              # as object (usual method)\n",
    "print(config[\"loss\"])           # as dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35efc750-c984-4a2d-b25e-446004eee784",
   "metadata": {},
   "source": [
    "## Creating a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce05335-fd4f-4903-90cd-6b047b8b9971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "def get_model(config)->keras.Model:\n",
    "    \"\"\" \n",
    "    Return a Model Based on the given Wandb config file\n",
    "    Warning: Your config file needs to match this creation Method\n",
    "\n",
    "    Parameters:\n",
    "        config (Dict)   wandb config with all the required field for the model creation\n",
    "\n",
    "    Returns:\n",
    "        model (tf.model)    Tensorflow model\n",
    "    \"\"\"\n",
    "\n",
    "    # build a model (read params from the config)\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Input(shape=(28,28)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(config.layer_1, activation=config.activation_hidden),\n",
    "        keras.layers.Dropout(config.dropout),\n",
    "        keras.layers.Dense(config.layer_2, activation=config.activation_output)\n",
    "        ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model(config)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee55c571-0e33-4279-aaa2-67099de65c2b",
   "metadata": {},
   "source": [
    "## Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd75b81c-ee16-4662-ad64-a2d606ea4de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model (with the config)\n",
    "model.compile(optimizer=config.optimizer,\n",
    "              loss=config.loss,\n",
    "              metrics=[config.metric]\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61da80ff-81bd-4549-b4f0-de4601056a55",
   "metadata": {},
   "source": [
    "## Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2bd791-484d-4390-96a8-070089d41250",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train, y_train = x_train[::5], y_train[::5]\n",
    "x_test, y_test = x_test[::20], y_test[::20]\n",
    "labels = [str(digit) for digit in range(np.max(y_train) + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d9aec1-2ca7-48f2-aadf-9efc460599c5",
   "metadata": {},
   "source": [
    "Plot a Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a649551f-5d60-415a-b9a9-7ebb0d35bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Display a sample image from the test set\n",
    "idx = 0  # you can change the index to see a different sample\n",
    "\n",
    "plt.imshow(x_test[idx], cmap='gray')\n",
    "plt.title(f\"True Label: {y_test[idx]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1915cc17-2b90-447e-8c5f-2f4952b01ade",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fae3fe-5f70-41bc-b4e0-12db40dc4eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory and file name for saving the model checkpoint\n",
    "checkpoint_filepath = f\"./models/{PROJECT_NAME}_Model_1_best.keras\"\n",
    "Path(\"./models\").mkdir(exist_ok=True)\n",
    "\n",
    "# WandbMetricsLogger will log train and validation metrics to wandb\n",
    "# WandbModelCheckpoint will upload model checkpoints to wandb\n",
    "history = model.fit(x=x_train, y=y_train,\n",
    "                    epochs=config.epoch,\n",
    "                    batch_size=config.batch_size,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[\n",
    "                      WandbMetricsLogger(log_freq=5),                   # link the metrics logger\n",
    "                      WandbModelCheckpoint(checkpoint_filepath,         # link the model logger\n",
    "                                           save_best_only=True)\n",
    "                    ])\n",
    "\n",
    "# -----------\n",
    "# Local Saving\n",
    "# -----------\n",
    "# After training, explicitly LOCALLY  save the final model\n",
    "\n",
    "final_model_filepath = f\"./models/{PROJECT_NAME}_Model1_final.keras\"\n",
    "model.save(final_model_filepath)\n",
    "print(f\"Model saved to {final_model_filepath}\")\n",
    "\n",
    "\n",
    "# ----------------\n",
    "# Save the Model online\n",
    "# -------------\n",
    "# Name of your Model Registry \n",
    "MODEL_REGISTRY = f\"{PROJECT_NAME}_Models\"\n",
    "\n",
    "# what to save (local path)\n",
    "model_artifact_path = Path(final_model_filepath)\n",
    "\n",
    "\n",
    "ARTIFACT_NAME_1 = f\"{PROJECT_NAME}_Model1_final.keras\" # name of the artifact (has to be loaded with this)\n",
    "\n",
    "# savibg file in project\n",
    "artifact1 = run.log_artifact(\n",
    "    model_artifact_path,\n",
    "    name=ARTIFACT_NAME_1,    # name of the artifact (has to be loaded with this)\n",
    "    type=\"model\",\n",
    ")\n",
    "\n",
    "# Add Metadata Info describing this model\n",
    "artifact1.metadata = {\"model_architecture\": \"two-layer\", \"tags\": [\"baseline\", \"dense\"]}\n",
    "\n",
    "# Optionally, you can link the artifact to a model registry for better organization\n",
    "run.link_artifact(\n",
    "    artifact=artifact1,\n",
    "    target_path=f\"wandb-registry-model/{MODEL_REGISTRY}\"     # Link the artifact (model) to the registry (with its own Artifact name)\n",
    ")\n",
    "\n",
    "# finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab24cc02-8f9c-466b-afb2-7b2dfb458234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a26704c-f97b-4619-9f2a-d0bc6904aa7c",
   "metadata": {},
   "source": [
    "## Testing area! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd572b6-ea80-4595-9265-243e3cce3346",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 7      # selection of test sample\n",
    "sample = x_test[idx] \n",
    "\n",
    "sample_input = sample.reshape((1,28,28))      # reshape to fit batch - format(1, 28, 28)\n",
    "\n",
    "# Predict and extract the predicted digit\n",
    "predictions = model.predict(sample_input)\n",
    "predicted_label = np.argmax(predictions, axis=1)[0]\n",
    "\n",
    "plt.imshow(sample, cmap='gray')\n",
    "plt.title(f\"Test Sample {idx:03}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(f\"Predicted Label: {predicted_label}\")\n",
    "print(f\"True Label: {y_test[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2e5d75-7aef-4392-9ab8-41e5cb6c7d30",
   "metadata": {},
   "source": [
    "## Training a New Model in the Same Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77977413-b33b-4f8f-802f-7f15f59ec400",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NR = 1\n",
    "\n",
    "# Initialize a new wandb run for Model 2\n",
    "run = wandb.init(project=PROJECT_NAME,\n",
    "                 name=f\"Model_2_{RUN_NR}\",\n",
    "                 config={\n",
    "                        \"layer_1\": 512,\n",
    "                        \"activation_1\": \"relu\",\n",
    "                        \"layer_2\": 256,\n",
    "                        \"activation_2\": \"relu\",\n",
    "                        \"layer_3\": 10,\n",
    "                        \"activation_3\": \"softmax\",\n",
    "                        \"epoch\": 5,\n",
    "                        \"batch_size\": 32,\n",
    "                        \"dropout\": 0.2,  \n",
    "                        \"optimizer\": \"sgd\",\n",
    "                        \"loss\": \"sparse_categorical_crossentropy\",\n",
    "                        \"metric\": \"accuracy\",\n",
    "                    })\n",
    "\n",
    "config2 = wandb.config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dfe4bf-cdb0-45e8-ae6f-f9f841f23f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer=config2.optimizer, loss=config2.loss, metrics=[config2.metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f48631-3e59-44db-9ff8-ebc24b778f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NR = 1\n",
    "\n",
    "# Set the directory and file name for LOCAL saving the model checkpoint\n",
    "checkpoint_filepath2 = f\"./models/{PROJECT_NAME}_Model2_best.keras\"\n",
    "\n",
    "# WandbMetricsLogger will log train and validation metrics to wandb\n",
    "# WandbModelCheckpoint will upload model checkpoints to wandb\n",
    "history = model.fit(x=x_train, y=y_train,\n",
    "                    epochs=config.epoch,\n",
    "                    batch_size=config.batch_size,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[\n",
    "                      WandbMetricsLogger(log_freq=5),\n",
    "                      WandbModelCheckpoint(checkpoint_filepath2,\n",
    "                                           save_best_only=True)\n",
    "                    ])\n",
    "\n",
    "# -----------\n",
    "# Local Saving\n",
    "# -----------\n",
    "# After training, explicitly LOCALLY  save the final model\n",
    "final_model_filepath2 = f\"./models/{PROJECT_NAME}_Model2_final.keras\"\n",
    "model.save(final_model_filepath2)\n",
    "print(f\"Model saved to {final_model_filepath2}\")\n",
    "\n",
    "# ----------------\n",
    "# Save the Model online\n",
    "# -------------\n",
    "# what to save (local path)\n",
    "model_artifact_path = Path(final_model_filepath2)\n",
    "\n",
    "ARTIFACT_NAME_2 = f\"{PROJECT_NAME}_Model2_final.keras\"\n",
    "# logging the file in the project\n",
    "logged_artifact = run.log_artifact(\n",
    "    model_artifact_path,\n",
    "    name=ARTIFACT_NAME_2,\n",
    "    type=\"model\",\n",
    ")\n",
    "\n",
    "# Optionally, you can link the artifact to a model registry for better organization\n",
    "# Name of your Model Registry \n",
    "MODEL_REGISTRY = f\"{PROJECT_NAME}_Models\"\n",
    "run.link_artifact(\n",
    "    artifact=logged_artifact,\n",
    "    target_path=f\"wandb-registry-model/{MODEL_REGISTRY}\"\n",
    ")\n",
    "\n",
    "# finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d0743-9d77-4f9a-b8de-a07b77aef104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
