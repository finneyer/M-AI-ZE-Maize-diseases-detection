{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d11444d-4a37-4242-a2dd-64a83c721bf8",
   "metadata": {},
   "source": [
    "# Training Yolov11 with RAAD\n",
    "Training Yolo11n Model wtih Metric RAAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9e8f51-7c69-4526-a291-9aaa1633d950",
   "metadata": {},
   "source": [
    "In this Notebook a Yolo Model will be Trained on the Metric RAAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd99517-1d1a-42f8-acd9-8b7f78c2cd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /opt/conda/lib/python3.12/site-packages (8.3.142)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.12/site-packages (0.19.11)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.1.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (1.15.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (0.21.0+cu124)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from ultralytics) (6.1.1)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.12/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.12/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.12/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (5.28.3)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.10.6)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.29.1)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.12/site-packages (from wandb) (1.3.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from wandb) (75.8.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.12/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Requirement already satisfied: dotenv in /opt/conda/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.12/site-packages (from dotenv) (1.1.0)\n",
      "Requirement already satisfied: shapely in /opt/conda/lib/python3.12/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.12/site-packages (from shapely) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ultralytics wandb\n",
    "!pip install dotenv\n",
    "!pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ab02345-a3f0-424f-9630-40700ac65d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import wandb\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.metrics import Metric\n",
    "from ultralytics.engine.trainer import BaseTrainer\n",
    "from tqdm.notebook import tqdm\n",
    "from shapely.geometry import box, MultiPolygon\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11a3cd17-1d51-4292-bc75-36d17d218d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONDict(\"/home/jovyan/.config/Ultralytics/settings.json\"):\n",
      "{\n",
      "  \"settings_version\": \"0.0.6\",\n",
      "  \"datasets_dir\": \"/home/jovyan/DSPRO2/M-AI-ZE-Maize-diseases-detection/notebooks/datasets\",\n",
      "  \"weights_dir\": \"weights\",\n",
      "  \"runs_dir\": \"runs\",\n",
      "  \"uuid\": \"8a115bbf5049f0fe55cf2ccd8be54ca8bfded6b963fd272724a959bb525556d2\",\n",
      "  \"sync\": true,\n",
      "  \"api_key\": \"\",\n",
      "  \"openai_api_key\": \"\",\n",
      "  \"clearml\": true,\n",
      "  \"comet\": true,\n",
      "  \"dvc\": true,\n",
      "  \"hub\": true,\n",
      "  \"mlflow\": true,\n",
      "  \"neptune\": true,\n",
      "  \"raytune\": true,\n",
      "  \"tensorboard\": false,\n",
      "  \"wandb\": true,\n",
      "  \"vscode_msg\": true,\n",
      "  \"openvino_msg\": true\n",
      "}\n",
      "💡 Learn more about Ultralytics Settings at https://docs.ultralytics.com/quickstart/#ultralytics-settings\n"
     ]
    }
   ],
   "source": [
    "# Enable W&B logging for Ultralytics\n",
    "!yolo settings wandb=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fefa102-b160-42c1-b14a-474ce0149f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WANDB_API_KEY: [69ca...]\n"
     ]
    }
   ],
   "source": [
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get and print the WANDB_API_KEY\n",
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "print(f\"WANDB_API_KEY: [{wandb_api_key[:4]}...]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7945424-eadb-4480-af0c-37eb29d3c99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=wandb_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c89f480-b2c4-43fa-90a5-09446cfd786e",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "953504ea-b0d4-483a-927f-1472d9511ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits\"\n",
    "splits = [\"SID01\", \"SID02\", \"SID03\"]\n",
    "test_csv_path = base_path + \"/SID01/labels/test/bboxes_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "836ac1c0-6369-41f6-8713-8d5c9177482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Split: SID01\n",
      "  Dataset Path: /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01 - Existiert: True\n",
      "  YAML Path: /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/data.yaml - Existiert: True\n",
      "  YAML Inhalt: dict_keys(['path', 'train', 'val', 'test', 'names'])\n",
      "  Train: images/train\n",
      "  Val: images/val\n",
      "  Test: images/test\n",
      "  NC: None\n",
      "  Names: {0: 'lesion'}\n",
      "\n",
      "Check Split: SID02\n",
      "  Dataset Path: /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID02 - Existiert: True\n",
      "  YAML Path: /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID02/data.yaml - Existiert: False\n",
      "\n",
      "Check Split: SID03\n",
      "  Dataset Path: /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID03 - Existiert: True\n",
      "  YAML Path: /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID03/data.yaml - Existiert: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for split in splits:\n",
    "    dataset_path = os.path.join(base_path, split)\n",
    "    yaml_path = os.path.join(dataset_path, \"data.yaml\")\n",
    "    \n",
    "    print(f\"Check Split: {split}\")\n",
    "    print(f\"  Dataset Path: {dataset_path} - Existiert: {os.path.exists(dataset_path)}\")\n",
    "    print(f\"  YAML Path: {yaml_path} - Existiert: {os.path.exists(yaml_path)}\")\n",
    "\n",
    "    if os.path.exists(yaml_path):\n",
    "        with open(yaml_path, 'r') as f:\n",
    "            data_yaml = yaml.safe_load(f)\n",
    "            print(f\"  YAML Inhalt: {data_yaml.keys()}\")\n",
    "            print(f\"  Train: {data_yaml.get('train')}\")\n",
    "            print(f\"  Val: {data_yaml.get('val')}\")\n",
    "            print(f\"  Test: {data_yaml.get('test')}\")\n",
    "            print(f\"  NC: {data_yaml.get('nc')}\")\n",
    "            print(f\"  Names: {data_yaml.get('names')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b2b48b-9a1e-41f0-b606-c7e834f90440",
   "metadata": {},
   "source": [
    "## RAAD Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bea30e24-dcef-4cb4-b3d3-6860c47b3f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_raad(pred_boxes, true_boxes, img_width=640, img_height=640, epsilon=1e-6, normalize=True):\n",
    "    \"\"\"\n",
    "    Calculate RAAD (Relative Affected Area Difference) metric\n",
    "    \n",
    "    Args:\n",
    "        pred_boxes: List of predicted boxes in format [x1, y1, x2, y2]\n",
    "        true_boxes: List of ground truth boxes in format [x1, y1, x2, y2]\n",
    "        img_width: Width of the image\n",
    "        img_height: Height of the image\n",
    "        epsilon: Small value to avoid division by zero\n",
    "        normalize: Whether to normalize coordinates from 0-1 to image dimensions\n",
    "        \n",
    "    Returns:\n",
    "        RAAD value (lower is better), Area of predictions, Area of ground truth\n",
    "    \"\"\"\n",
    "    if len(pred_boxes) == 0 and len(true_boxes) == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    if len(pred_boxes) == 0:\n",
    "        return 1.0, 0.0, sum([(box[2]-box[0])*(box[3]-box[1]) for box in true_boxes])\n",
    "    if len(true_boxes) == 0:\n",
    "        return 1.0, sum([(box[2]-box[0])*(box[3]-box[1]) for box in pred_boxes]), 0.0\n",
    "    \n",
    "    if normalize:\n",
    "        pred_boxes = [[box[0]*img_width, box[1]*img_height, \n",
    "                      box[2]*img_width, box[3]*img_height] for box in pred_boxes]\n",
    "        true_boxes = [[box[0]*img_width, box[1]*img_height, \n",
    "                      box[2]*img_width, box[3]*img_height] for box in true_boxes]\n",
    "    \n",
    "    pred_polygons = [box(b[0], b[1], b[2], b[3]) for b in pred_boxes]\n",
    "    true_polygons = [box(b[0], b[1], b[2], b[3]) for b in true_boxes]\n",
    "    \n",
    "    if pred_polygons:\n",
    "        pred_multipolygon = MultiPolygon(pred_polygons).buffer(0)\n",
    "    else:\n",
    "        pred_multipolygon = MultiPolygon([])\n",
    "        \n",
    "    if true_polygons:\n",
    "        true_multipolygon = MultiPolygon(true_polygons).buffer(0)\n",
    "    else:\n",
    "        true_multipolygon = MultiPolygon([])\n",
    "    \n",
    "    pred_area = pred_multipolygon.area\n",
    "    true_area = true_multipolygon.area\n",
    "    \n",
    "    area_diff = abs(pred_area - true_area)\n",
    "    raad = area_diff / max(true_area, epsilon)\n",
    "    \n",
    "    return raad, pred_area, true_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3d98ea3-7547-4f8d-975e-3423da88a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAADMetric:\n",
    "    \"\"\"RAAD (Relative Affected Area Difference) metric calculator\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.raad_values = []\n",
    "        self.pred_areas = []\n",
    "        self.true_areas = []\n",
    "        \n",
    "    def calculate_raad(self, pred_boxes, true_boxes, img_width=640, img_height=640, epsilon=1e-6, normalize=True):\n",
    "        \"\"\"Calculate RAAD metric between predicted and true boxes\"\"\"\n",
    "        if len(pred_boxes) == 0 and len(true_boxes) == 0:\n",
    "            return 0.0, 0.0, 0.0\n",
    "        if len(pred_boxes) == 0:\n",
    "            true_area = sum([(box[2]-box[0])*(box[3]-box[1]) for box in true_boxes])\n",
    "            return 1.0, 0.0, true_area\n",
    "        if len(true_boxes) == 0:\n",
    "            pred_area = sum([(box[2]-box[0])*(box[3]-box[1]) for box in pred_boxes])\n",
    "            return 1.0, pred_area, 0.0\n",
    "        \n",
    "        if normalize:\n",
    "            pred_boxes = [[box[0]*img_width, box[1]*img_height, \n",
    "                          box[2]*img_width, box[3]*img_height] for box in pred_boxes]\n",
    "            true_boxes = [[box[0]*img_width, box[1]*img_height, \n",
    "                          box[2]*img_width, box[3]*img_height] for box in true_boxes]\n",
    "        \n",
    "        try:\n",
    "            pred_polygons = [box(b[0], b[1], b[2], b[3]) for b in pred_boxes if b[2] > b[0] and b[3] > b[1]]\n",
    "            true_polygons = [box(b[0], b[1], b[2], b[3]) for b in true_boxes if b[2] > b[0] and b[3] > b[1]]\n",
    "            \n",
    "            pred_multipolygon = MultiPolygon(pred_polygons).buffer(0) if pred_polygons else MultiPolygon([])\n",
    "            true_multipolygon = MultiPolygon(true_polygons).buffer(0) if true_polygons else MultiPolygon([])\n",
    "            \n",
    "            pred_area = pred_multipolygon.area\n",
    "            true_area = true_multipolygon.area\n",
    "            \n",
    "            area_diff = abs(pred_area - true_area)\n",
    "            raad = area_diff / max(true_area, epsilon)\n",
    "            \n",
    "            return raad, pred_area, true_area\n",
    "        except Exception as e:\n",
    "            print(f\"Error in RAAD calculation: {e}\")\n",
    "            return 1.0, 0.0, 0.0\n",
    "        \n",
    "    def process_batch(self, detections, labels, img_width=640, img_height=640):\n",
    "        \"\"\"Process one batch of detections and labels\"\"\"\n",
    "        batch_raad = []\n",
    "        \n",
    "        if detections is None or len(detections) == 0:\n",
    "            detections = []\n",
    "        if labels is None or len(labels) == 0:\n",
    "            labels = []\n",
    "            \n",
    "        pred_boxes = []\n",
    "        if len(detections) > 0:\n",
    "            if torch.is_tensor(detections):\n",
    "                detections = detections.cpu().numpy()\n",
    "            for det in detections:\n",
    "                if len(det) >= 4:\n",
    "                    pred_boxes.append([det[0], det[1], det[2], det[3]])\n",
    "        \n",
    "        true_boxes = []\n",
    "        if len(labels) > 0:\n",
    "            if torch.is_tensor(labels):\n",
    "                labels = labels.cpu().numpy()\n",
    "            for label in labels:\n",
    "                if len(label) >= 5:\n",
    "                    # Labels format: [cls, cx, cy, w, h] normalized\n",
    "                    cls, cx, cy, w, h = label[:5]\n",
    "                    x1 = (cx - w/2) * img_width\n",
    "                    y1 = (cy - h/2) * img_height\n",
    "                    x2 = (cx + w/2) * img_width\n",
    "                    y2 = (cy + h/2) * img_height\n",
    "                    true_boxes.append([x1, y1, x2, y2])\n",
    "        \n",
    "        raad, pred_area, true_area = self.calculate_raad(\n",
    "            pred_boxes, true_boxes, img_width, img_height, normalize=False\n",
    "        )\n",
    "        \n",
    "        self.raad_values.append(raad)\n",
    "        self.pred_areas.append(pred_area)\n",
    "        self.true_areas.append(true_area)\n",
    "        \n",
    "        return raad\n",
    "        \n",
    "    def mean_raad(self):\n",
    "        \"\"\"Calculate mean RAAD over all processed batches\"\"\"\n",
    "        if not self.raad_values:\n",
    "            return 0.0\n",
    "        return sum(self.raad_values) / len(self.raad_values)\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset metrics for new evaluation\"\"\"\n",
    "        self.raad_values = []\n",
    "        self.pred_areas = []\n",
    "        self.true_areas = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b092b930-6d5e-4b0d-a7b2-8bfcebcce389",
   "metadata": {},
   "source": [
    "## Custom Yolo Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f6507bd-779c-422a-a6e0-c802487d4d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDetectionValidator(DetectionValidator):\n",
    "    \"\"\"Custom validator that calculates RAAD during validation\"\"\"\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.raad_metric = RAADMetric()\n",
    "        \n",
    "    def init_metrics(self, model):\n",
    "        \"\"\"Initialize metrics including RAAD\"\"\"\n",
    "        super().init_metrics(model)\n",
    "        self.raad_metric.reset()\n",
    "        \n",
    "    def postprocess(self, preds):\n",
    "        \"\"\"Postprocess predictions and calculate RAAD\"\"\"\n",
    "        processed_preds = super().postprocess(preds)\n",
    "        \n",
    "        try:\n",
    "            if hasattr(self, 'batch') and self.batch is not None:\n",
    "                # Get current batch labels\n",
    "                labels = self.batch.get('bboxes', None)\n",
    "                \n",
    "                if labels is not None and processed_preds is not None:\n",
    "                    for i, pred in enumerate(processed_preds):\n",
    "                        if i < len(labels) and labels[i] is not None:\n",
    "                            # Convert predictions to boxes\n",
    "                            if pred is not None and len(pred) > 0:\n",
    "                                pred_boxes = pred[:, :4].cpu().numpy()  # x1, y1, x2, y2\n",
    "                            else:\n",
    "                                pred_boxes = []\n",
    "                            \n",
    "                            if len(labels[i]) > 0:\n",
    "                                label_boxes = []\n",
    "                                for label in labels[i]:\n",
    "                                    if len(label) >= 5:\n",
    "                                        cls, cx, cy, w, h = label[:5]\n",
    "                                        x1 = (cx - w/2) * self.args.imgsz\n",
    "                                        y1 = (cy - h/2) * self.args.imgsz\n",
    "                                        x2 = (cx + w/2) * self.args.imgsz\n",
    "                                        y2 = (cy + h/2) * self.args.imgsz\n",
    "                                        label_boxes.append([x1, y1, x2, y2])\n",
    "                            else:\n",
    "                                label_boxes = []\n",
    "                            \n",
    "                            raad, _, _ = self.raad_metric.calculate_raad(\n",
    "                                pred_boxes.tolist() if len(pred_boxes) > 0 else [],\n",
    "                                label_boxes,\n",
    "                                self.args.imgsz, self.args.imgsz,\n",
    "                                normalize=False\n",
    "                            )\n",
    "                            \n",
    "                            self.raad_metric.raad_values.append(raad)\n",
    "                            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in RAAD calculation during validation: {e}\")\n",
    "            \n",
    "        return processed_preds\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get validation statistics including RAAD\"\"\"\n",
    "        stats = super().get_stats()\n",
    "        \n",
    "        raad_mean = self.raad_metric.mean_raad()\n",
    "        stats = list(stats) if isinstance(stats, tuple) else [stats]\n",
    "        stats.append(raad_mean)\n",
    "        \n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc1b008f-f32b-4356-9fc2-c3d4b6b135e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAADLoss(nn.Module):\n",
    "    \"\"\"RAAD-based loss function for YOLO training\"\"\"\n",
    "    \n",
    "    def __init__(self, weight=1.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "        self.raad_metric = RAADMetric()\n",
    "        \n",
    "    def forward(self, pred_boxes, true_boxes, img_size=640):\n",
    "        \"\"\"\n",
    "        Calculate RAAD loss\n",
    "        \n",
    "        Args:\n",
    "            pred_boxes: Predicted boxes tensor [N, 4] in xyxy format\n",
    "            true_boxes: Ground truth boxes tensor [M, 4] in xyxy format\n",
    "            img_size: Image size for normalization\n",
    "            \n",
    "        Returns:\n",
    "            RAAD loss tensor\n",
    "        \"\"\"\n",
    "        if pred_boxes.numel() == 0 and true_boxes.numel() == 0:\n",
    "            return torch.tensor(0.0, device=pred_boxes.device, requires_grad=True)\n",
    "            \n",
    "\n",
    "        pred_np = pred_boxes.detach().cpu().numpy() if pred_boxes.numel() > 0 else []\n",
    "        true_np = true_boxes.detach().cpu().numpy() if true_boxes.numel() > 0 else []\n",
    "        \n",
    "        raad, _, _ = self.raad_metric.calculate_raad(\n",
    "            pred_np.tolist() if len(pred_np) > 0 else [],\n",
    "            true_np.tolist() if len(true_np) > 0 else [],\n",
    "            img_size, img_size, normalize=False\n",
    "        )\n",
    "        \n",
    "        raad_tensor = torch.tensor(raad, device=pred_boxes.device, requires_grad=True)\n",
    "        \n",
    "        return raad_tensor * self.weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "408fc7c7-313a-467c-b4d4-c5accbc99198",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomYOLOTrainer:\n",
    "    \"\"\"Custom YOLO trainer with RAAD metric integration\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path=\"yolo11n.pt\", raad_weight=0.1):\n",
    "        self.model = YOLO(model_path)\n",
    "        self.raad_metric = RAADMetric()\n",
    "        self.raad_loss = RAADLoss(weight=raad_weight)\n",
    "        self.raad_weight = raad_weight\n",
    "        \n",
    "    def train_with_raad(self, data_yaml, epochs=10, batch=16, lr=0.01, project=\"maize_detection\", name=\"raad_training\"):\n",
    "        \"\"\"Train YOLO model with RAAD metric tracking\"\"\"\n",
    "        \n",
    "        wandb_run = wandb.init(\n",
    "            project=project,\n",
    "            name=name,\n",
    "            config={\n",
    "                \"epochs\": epochs,\n",
    "                \"batch_size\": batch,\n",
    "                \"learning_rate\": lr,\n",
    "                \"raad_weight\": self.raad_weight,\n",
    "                \"model\": str(type(self.model.model))\n",
    "            },\n",
    "            reinit=True\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            class RAADCallback:\n",
    "                def __init__(self, raad_metric, wandb_run):\n",
    "                    self.raad_metric = raad_metric\n",
    "                    self.wandb_run = wandb_run\n",
    "                    self.epoch_raad_values = []\n",
    "                \n",
    "                def on_train_epoch_start(self, trainer):\n",
    "                    self.raad_metric.reset()\n",
    "                    self.epoch_raad_values = []\n",
    "                \n",
    "                def on_val_start(self, validator):\n",
    "                    self.raad_metric.reset()\n",
    "                \n",
    "                def on_val_batch_end(self, validator):\n",
    "                    # For now, we'll skip per-batch RAAD calculation during training\n",
    "                    # and rely on post-training evaluation\n",
    "                    pass\n",
    "                \n",
    "                def on_val_end(self, validator):\n",
    "                    if self.epoch_raad_values:\n",
    "                        avg_raad = sum(self.epoch_raad_values) / len(self.epoch_raad_values)\n",
    "                    else:\n",
    "                        avg_raad = self.raad_metric.mean_raad()\n",
    "                    \n",
    "                    current_epoch = getattr(validator, 'epoch', 0)\n",
    "                    \n",
    "                    if self.wandb_run:\n",
    "                        self.wandb_run.log({\n",
    "                            \"val/raad\": avg_raad,\n",
    "                            \"epoch\": current_epoch\n",
    "                        })\n",
    "                    \n",
    "                    print(f\"Epoch {current_epoch} - Validation RAAD: {avg_raad:.4f}\")\n",
    "            \n",
    "            callback = RAADCallback(self.raad_metric, wandb_run)\n",
    "            \n",
    "            # Add callbacks to model\n",
    "            self.model.add_callback(\"on_train_epoch_start\", callback.on_train_epoch_start)\n",
    "            self.model.add_callback(\"on_val_start\", callback.on_val_start)\n",
    "            self.model.add_callback(\"on_val_batch_end\", callback.on_val_batch_end)\n",
    "            self.model.add_callback(\"on_val_end\", callback.on_val_end)\n",
    "            \n",
    "            results = self.model.train(\n",
    "                data=data_yaml,\n",
    "                epochs=epochs,\n",
    "                imgsz=640,\n",
    "                lr0=lr,\n",
    "                batch=batch,\n",
    "                name=name,\n",
    "                project=project,\n",
    "                exist_ok=True,\n",
    "                verbose=True\n",
    "            )\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        finally:\n",
    "            if wandb_run:\n",
    "                wandb_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2838ed3-e8af-4f4d-a8ec-2815249d4fba",
   "metadata": {},
   "source": [
    "## Training with RAAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02f9813b-ca41-4c15-b787-37788d9ac0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_raad(model_type=\"yolo11n.pt\", split=\"SID01\", epochs=10, batch=16, lr=0.01, raad_weight=0.1):\n",
    "    \"\"\"\n",
    "    Enhanced training function with RAAD metric integration\n",
    "    \n",
    "    Args:\n",
    "        model_type: YOLO model type/path\n",
    "        split: Data split name\n",
    "        epochs: Number of training epochs\n",
    "        batch: Batch size\n",
    "        lr: Learning rate\n",
    "        raad_weight: Weight for RAAD loss component\n",
    "        \n",
    "    Returns:\n",
    "        Path to trained model weights\n",
    "    \"\"\"\n",
    "    base_path = \"/exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits\"\n",
    "    dataset_yaml = f\"{base_path}/{split}/data.yaml\"\n",
    "    \n",
    "    model_name = model_type.split('.')[0]\n",
    "    run_name = f\"{model_name}_{split}_raad_w{raad_weight}_e{epochs}\"\n",
    "    \n",
    "    try:\n",
    "        trainer = CustomYOLOTrainer(model_type, raad_weight=raad_weight)\n",
    "        \n",
    "        results = trainer.train_with_raad(\n",
    "            data_yaml=dataset_yaml,\n",
    "            epochs=epochs,\n",
    "            batch=batch,\n",
    "            lr=lr,\n",
    "            project=\"maize_detection_raad\",\n",
    "            name=run_name\n",
    "        )\n",
    "        \n",
    "        potential_paths = [\n",
    "            f\"runs/detect/{run_name}/weights/best.pt\",\n",
    "            f\"maize_detection_raad/{run_name}/weights/best.pt\",\n",
    "            f\"runs/train/{run_name}/weights/best.pt\",\n",
    "            f\"maize_detection_raad/{run_name}/weights/last.pt\"\n",
    "        ]\n",
    "        \n",
    "        weights_path = None\n",
    "        for path in potential_paths:\n",
    "            if os.path.exists(path):\n",
    "                weights_path = path\n",
    "                print(f\"Found trained model at: {weights_path}\")\n",
    "                break\n",
    "        \n",
    "        if weights_path is None:\n",
    "            print(\"Warning: Could not find trained weights\")\n",
    "            return model_type\n",
    "            \n",
    "        return weights_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during RAAD training: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd2cef-08b1-4cb8-8895-84db11e5dc21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09df7fba-d83d-4a5c-8b24-251dd5abf3c6",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d84190c5-59f3-4031-9f45-7bb7d9d595bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bounding_boxes_from_csv(csv_path):\n",
    "    \"\"\"\n",
    "    Load bounding boxes from a single CSV file.\n",
    "    \n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary where keys are image names and values are lists of bounding boxes.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, header=None, skiprows=1)\n",
    "    bounding_boxes = {}\n",
    "    for _, row in df.iterrows():\n",
    "        img_name = row[0]  # Bildname\n",
    "        x1, y1, x2, y2 = map(int, [row[1], row[2], row[3], row[4]])\n",
    "        if img_name not in bounding_boxes:\n",
    "            bounding_boxes[img_name] = []\n",
    "        bounding_boxes[img_name].append((x1, y1, x2, y2))\n",
    "    print(f\"Loaded bounding boxes for {len(bounding_boxes)} images.\")\n",
    "    return bounding_boxes\n",
    "\n",
    "def suppress_yolo_logging():\n",
    "    \"\"\"Suppress the YOLO logging temporarily.\"\"\"\n",
    "    logger = logging.getLogger(\"ultralytics\")\n",
    "    original_level = logger.level\n",
    "    logger.setLevel(logging.ERROR) \n",
    "    return logger, original_level\n",
    "\n",
    "def restore_yolo_logging(logger, original_level):\n",
    "    \"\"\"Restore the YOLO logging to its original level.\"\"\"\n",
    "    logger.setLevel(original_level)\n",
    "\n",
    "def evaluate_test_raad(model_path, bounding_boxes, split=\"SID01\"):\n",
    "    \"\"\"\n",
    "    Evaluate a trained model on test data with RAAD metric.\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Path to the YOLO model file.\n",
    "        bounding_boxes (dict): Dictionary with image names as keys and box lists as values.\n",
    "        split (str): Data split name.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (DataFrame with results, average RAAD value)\n",
    "    \"\"\"\n",
    "    model_name = os.path.basename(model_path).split('.')[0]\n",
    "    \n",
    "    run = wandb.init(project=\"maize_detection_test\", \n",
    "                    name=f\"test_evaluation_{model_name}_{split}\",\n",
    "                    config={\"model_path\": model_path, \"split\": split})\n",
    "    \n",
    "    try:\n",
    "        base_path = \"/exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits\"\n",
    "        test_images_dir = f\"{base_path}/{split}/images/test\"\n",
    "        \n",
    "        model = YOLO(model_path)\n",
    "        raad_calculator = RAADMetric()  # Use our RAADMetric class\n",
    "        \n",
    "        results = {\n",
    "            'image': [],\n",
    "            'raad': [],\n",
    "            'pred_area': [],\n",
    "            'true_area': [],\n",
    "            'prediction_count': [],\n",
    "            'truth_count': []\n",
    "        }\n",
    "        \n",
    "        test_images = [f for f in os.listdir(test_images_dir) if f.endswith(('.jpg', '.png'))]\n",
    "        \n",
    "        for img_file in tqdm(test_images, desc=\"Evaluating test images\"):\n",
    "            img_path = os.path.join(test_images_dir, img_file)\n",
    "            \n",
    "            if img_file not in bounding_boxes:\n",
    "                print(f\"No ground truth for image: {img_file}\")\n",
    "                continue\n",
    "            \n",
    "            img = cv2.imread(img_path)\n",
    "            img_height, img_width = img.shape[:2]\n",
    "            \n",
    "            logger, original_level = suppress_yolo_logging()\n",
    "            try:\n",
    "                predictions = model.predict(img_path, save=False)\n",
    "            finally:\n",
    "                restore_yolo_logging(logger, original_level)\n",
    "            \n",
    "            pred_boxes = [\n",
    "                [int(box[0]), int(box[1]), int(box[2]), int(box[3])]\n",
    "                for r in predictions for box in r.boxes.xyxy.cpu().numpy()\n",
    "            ]\n",
    "            \n",
    "            true_boxes = list(bounding_boxes[img_file])  # Convert tuples to list\n",
    "            \n",
    "            raad, pred_area, true_area = raad_calculator.calculate_raad(\n",
    "                pred_boxes, true_boxes, img_width, img_height, normalize=False\n",
    "            )\n",
    "            \n",
    "            results['image'].append(img_file)\n",
    "            results['raad'].append(raad)\n",
    "            results['pred_area'].append(pred_area)\n",
    "            results['true_area'].append(true_area)\n",
    "            results['prediction_count'].append(len(pred_boxes))\n",
    "            results['truth_count'].append(len(true_boxes))\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        avg_raad = results_df['raad'].mean()\n",
    "        print(f\"Average RAAD on test set: {avg_raad:.4f}\")\n",
    "        run.log({\"test/avg_raad\": avg_raad})\n",
    "        run.finish()\n",
    "        \n",
    "        return results_df, avg_raad\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during RAAD evaluation: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        run.finish()\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98d8d7bb-c755-4a67-8c54-53b1aac040c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_raad_training_effectiveness(original_model, raad_trained_model, test_data_path, split=\"SID01\"):\n",
    "    \"\"\"\n",
    "    Compare RAAD performance between original and RAAD-trained models\n",
    "    \n",
    "    Args:\n",
    "        original_model: Path to original model\n",
    "        raad_trained_model: Path to RAAD-trained model\n",
    "        test_data_path: Path to test CSV file\n",
    "        split: Data split name\n",
    "        \n",
    "    Returns:\n",
    "        Comparison results dictionary\n",
    "    \"\"\"\n",
    "    print(\"Evaluating RAAD training effectiveness...\")\n",
    "    \n",
    "    bounding_boxes = load_bounding_boxes_from_csv(test_data_path)\n",
    "    \n",
    "    print(\"Evaluating original model...\")\n",
    "    orig_results, orig_raad = evaluate_test_raad(original_model, bounding_boxes, split)\n",
    "    \n",
    "    print(\"Evaluating RAAD-trained model...\")\n",
    "    raad_results, raad_trained_raad = evaluate_test_raad(raad_trained_model, bounding_boxes, split)\n",
    "    \n",
    "    if orig_raad is not None and raad_trained_raad is not None:\n",
    "        improvement = ((orig_raad - raad_trained_raad) / orig_raad) * 100\n",
    "        \n",
    "        results = {\n",
    "            \"original_raad\": orig_raad,\n",
    "            \"raad_trained_raad\": raad_trained_raad,\n",
    "            \"improvement_percent\": improvement,\n",
    "            \"original_results\": orig_results,\n",
    "            \"raad_trained_results\": raad_results\n",
    "        }\n",
    "        \n",
    "        print(f\"Original model RAAD: {orig_raad:.4f}\")\n",
    "        print(f\"RAAD-trained model RAAD: {raad_trained_raad:.4f}\")\n",
    "        print(f\"Improvement: {improvement:.2f}%\")\n",
    "        \n",
    "        wandb_run = wandb.init(\n",
    "            project=\"raad_training_comparison\",\n",
    "            name=f\"comparison_{split}\",\n",
    "            config={\"split\": split}\n",
    "        )\n",
    "        \n",
    "        wandb_run.log({\n",
    "            \"original_raad\": orig_raad,\n",
    "            \"raad_trained_raad\": raad_trained_raad,\n",
    "            \"improvement_percent\": improvement\n",
    "        })\n",
    "        \n",
    "        wandb_run.finish()\n",
    "        \n",
    "        return results\n",
    "    else:\n",
    "        print(\"Error: Could not evaluate one or both models\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f872cb-5956-42cf-ad37-87ee8577a1e0",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e552d749-8486-44f1-9162-0dbc38c7a756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/DSPRO2/M-AI-ZE-Maize-diseases-detection/notebooks/wandb/run-20250522_215309-v5rz1cer</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_raad/runs/v5rz1cer' target=\"_blank\">yolo11n_SID01_raad_w0.1_e5</a></strong> to <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_raad' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_raad' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_raad</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_raad/runs/v5rz1cer' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_raad/runs/v5rz1cer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.142 🚀 Python-3.12.8 torch-2.6.0+cu124 CUDA:0 (NVIDIA A16, 14891MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=5, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11n_SID01_raad_w0.1_e5, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=maize_detection_raad, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=maize_detection_raad/yolo11n_SID01_raad_w0.1_e5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1846.6±535.2 MB/s, size: 59.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/labels/train.cache... 10858 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10858/10858 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1728.6±782.3 MB/s, size: 56.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/labels/val.cache... 1357 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1357/1357 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to maize_detection_raad/yolo11n_SID01_raad_w0.1_e5/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mmaize_detection_raad/yolo11n_SID01_raad_w0.1_e5\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      2.83G      2.273      2.367      1.568        104        640: 100%|██████████| 679/679 [02:43<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  37%|███▋      | 16/43 [00:25<01:05,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 43/43 [01:08<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.462      0.378      0.367      0.148\n",
      "Epoch 0 - Validation RAAD: 0.0000\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 2. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 2. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 2. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 2. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 2. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 2. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "        2/5      3.37G      2.069      1.858       1.44        134        640: 100%|██████████| 679/679 [02:38<00:00,  4.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 43/43 [01:47<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.472      0.383      0.369      0.151\n",
      "Epoch 0 - Validation RAAD: 0.0000\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 3. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "        3/5      3.38G      2.022      1.773      1.414        118        640: 100%|██████████| 679/679 [02:36<00:00,  4.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 43/43 [00:53<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.541      0.427      0.435       0.19\n",
      "Epoch 0 - Validation RAAD: 0.0000\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 4. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "        4/5      3.38G      1.956      1.692      1.373         54        640: 100%|██████████| 679/679 [02:37<00:00,  4.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  40%|███▉      | 17/43 [00:30<01:12,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 43/43 [01:20<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.552      0.456      0.471      0.208\n",
      "Epoch 0 - Validation RAAD: 0.0000\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 5. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "        5/5      3.38G      1.896      1.617      1.337         86        640: 100%|██████████| 679/679 [02:35<00:00,  4.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 43/43 [00:50<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668       0.58      0.478      0.505      0.231\n",
      "Epoch 0 - Validation RAAD: 0.0000\n",
      "\n",
      "5 epochs completed in 0.322 hours.\n",
      "Optimizer stripped from maize_detection_raad/yolo11n_SID01_raad_w0.1_e5/weights/last.pt, 5.5MB\n",
      "Optimizer stripped from maize_detection_raad/yolo11n_SID01_raad_w0.1_e5/weights/best.pt, 5.5MB\n",
      "\n",
      "Validating maize_detection_raad/yolo11n_SID01_raad_w0.1_e5/weights/best.pt...\n",
      "Ultralytics 8.3.142 🚀 Python-3.12.8 torch-2.6.0+cu124 CUDA:0 (NVIDIA A16, 14891MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 6. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 43/43 [00:55<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.579      0.479      0.505      0.231\n",
      "Epoch 0 - Validation RAAD: 0.0000\n",
      "Speed: 0.3ms preprocess, 3.8ms inference, 0.0ms loss, 29.7ms postprocess per image\n",
      "Results saved to \u001b[1mmaize_detection_raad/yolo11n_SID01_raad_w0.1_e5\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁</td></tr><tr><td>lr/pg0</td><td>▃▇█▅▁</td></tr><tr><td>lr/pg1</td><td>▃▇█▅▁</td></tr><tr><td>lr/pg2</td><td>▃▇█▅▁</td></tr><tr><td>train/box_loss</td><td>█▄▃▂▁</td></tr><tr><td>train/cls_loss</td><td>█▃▂▂▁</td></tr><tr><td>train/dfl_loss</td><td>█▄▃▂▁</td></tr><tr><td>val/raad</td><td>▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>lr/pg0</td><td>0.00042</td></tr><tr><td>lr/pg1</td><td>0.00042</td></tr><tr><td>lr/pg2</td><td>0.00042</td></tr><tr><td>train/box_loss</td><td>1.89639</td></tr><tr><td>train/cls_loss</td><td>1.61692</td></tr><tr><td>train/dfl_loss</td><td>1.33744</td></tr><tr><td>val/raad</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n_SID01_raad_w0.1_e5</strong> at: <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_raad/runs/v5rz1cer' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_raad/runs/v5rz1cer</a><br> View project at: <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_raad' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_raad</a><br>Synced 5 W&B file(s), 21 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250522_215309-v5rz1cer/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 5 that is less than the current step 7. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 5 that is less than the current step 7. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 5 that is less than the current step 7. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 5 that is less than the current step 7. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 5 that is less than the current step 7. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 5 that is less than the current step 7. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 5 that is less than the current step 7. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 5 that is less than the current step 7. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 5 that is less than the current step 7. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 5 that is less than the current step 7. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 5 that is less than the current step 7. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 5 that is less than the current step 7. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 5 that is less than the current step 7. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 5 that is less than the current step 7. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found trained model at: maize_detection_raad/yolo11n_SID01_raad_w0.1_e5/weights/best.pt\n",
      "RAAD-trained model saved at: maize_detection_raad/yolo11n_SID01_raad_w0.1_e5/weights/best.pt\n",
      "Evaluating RAAD training effectiveness...\n",
      "Loaded bounding boxes for 1358 images.\n",
      "Evaluating original model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/DSPRO2/M-AI-ZE-Maize-diseases-detection/notebooks/wandb/run-20250522_221449-3sjuhx2t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test/runs/3sjuhx2t' target=\"_blank\">test_evaluation_yolo11n_SID01</a></strong> to <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test/runs/3sjuhx2t' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test/runs/3sjuhx2t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d9f5ec6edf46e29704f70993634207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating test images:   0%|          | 0/1358 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RAAD on test set: 4.0873\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test/avg_raad</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test/avg_raad</td><td>4.08729</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test_evaluation_yolo11n_SID01</strong> at: <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test/runs/3sjuhx2t' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test/runs/3sjuhx2t</a><br> View project at: <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250522_221449-3sjuhx2t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RAAD-trained model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/DSPRO2/M-AI-ZE-Maize-diseases-detection/notebooks/wandb/run-20250522_222016-ddnn18fa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test/runs/ddnn18fa' target=\"_blank\">test_evaluation_best_SID01</a></strong> to <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test/runs/ddnn18fa' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test/runs/ddnn18fa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578784386cb04435b680bb301eba9fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating test images:   0%|          | 0/1358 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RAAD on test set: 0.9025\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test/avg_raad</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test/avg_raad</td><td>0.90251</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test_evaluation_best_SID01</strong> at: <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test/runs/ddnn18fa' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test/runs/ddnn18fa</a><br> View project at: <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250522_222016-ddnn18fa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model RAAD: 4.0873\n",
      "RAAD-trained model RAAD: 0.9025\n",
      "Improvement: 77.92%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/DSPRO2/M-AI-ZE-Maize-diseases-detection/notebooks/wandb/run-20250522_222554-e7ok2ktk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/raad_training_comparison/runs/e7ok2ktk' target=\"_blank\">comparison_SID01</a></strong> to <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/raad_training_comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/raad_training_comparison' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/raad_training_comparison</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/raad_training_comparison/runs/e7ok2ktk' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/raad_training_comparison/runs/e7ok2ktk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>improvement_percent</td><td>▁</td></tr><tr><td>original_raad</td><td>▁</td></tr><tr><td>raad_trained_raad</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>improvement_percent</td><td>77.91917</td></tr><tr><td>original_raad</td><td>4.08729</td></tr><tr><td>raad_trained_raad</td><td>0.90251</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comparison_SID01</strong> at: <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/raad_training_comparison/runs/e7ok2ktk' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/raad_training_comparison/runs/e7ok2ktk</a><br> View project at: <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/raad_training_comparison' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/raad_training_comparison</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250522_222554-e7ok2ktk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    raad_trained_path = train_model_with_raad(\n",
    "        model_type=\"yolo11n.pt\",\n",
    "        split=\"SID01\",\n",
    "        epochs=5,\n",
    "        batch=16,\n",
    "        lr=0.01,\n",
    "        raad_weight=0.1\n",
    "    )\n",
    "    \n",
    "    print(f\"RAAD-trained model saved at: {raad_trained_path}\")\n",
    "    \n",
    "    base_path = \"/exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits\"\n",
    "    test_csv_path = f\"{base_path}/SID01/labels/test/bboxes_test.csv\"\n",
    "    \n",
    "    comparison = evaluate_raad_training_effectiveness(\n",
    "        original_model=\"yolo11n.pt\",\n",
    "        raad_trained_model=raad_trained_path,\n",
    "        test_data_path=test_csv_path,\n",
    "        split=\"SID01\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17446d41-f9ff-4b35-95e2-59c24dca39f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
