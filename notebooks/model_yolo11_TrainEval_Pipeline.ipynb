{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d11444d-4a37-4242-a2dd-64a83c721bf8",
   "metadata": {},
   "source": [
    "# YOLOv11 Model Training and Evaluation for Maize Disease Detection\n",
    "\n",
    "This notebook provides a complete pipeline for training and evaluating YOLOv11 object detection models on the **maize lesion dataset**, structured across multiple dataset splits: `SID01`, `SID02`, and `SID03`.\n",
    "\n",
    "Key features of this pipeline include:\n",
    "\n",
    "- **Automated training** across different YOLO variants (`n`, `m`, `l`), batch sizes, and splits.\n",
    "- Support for:\n",
    "  - `SID02` subtype-specific training (`boom`, `drone`, `handheld`)\n",
    "  - `SID03` K-Fold cross-validation.\n",
    "- **Custom evaluation using the RAAD metric** (Relative Affected Area Difference), assessing bounding box area agreement between predictions and ground truth.\n",
    "- **Integration with Weights & Biases (wandb)** for:\n",
    "  - Tracking training runs and hyperparameters.\n",
    "  - Logging test metrics and qualitative predictions.\n",
    "  - Uploading per-image evaluation tables and **collage visualizations** for best/worst cases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd99517-1d1a-42f8-acd9-8b7f78c2cd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /opt/conda/lib/python3.12/site-packages (8.3.146)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.12/site-packages (0.19.11)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (3.10.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.7.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (0.22.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.12/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.12/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.12/site-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (4.25.6)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.29.1)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.12/site-packages (from wandb) (1.3.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from wandb) (78.1.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.12/site-packages (from wandb) (4.13.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Requirement already satisfied: dotenv in /opt/conda/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.12/site-packages (from dotenv) (1.1.0)\n",
      "Requirement already satisfied: shapely in /opt/conda/lib/python3.12/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.12/site-packages (from shapely) (1.26.4)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.12/site-packages (0.19.11)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.12/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.12/site-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (4.25.6)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.12/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.29.1)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.12/site-packages (from wandb) (1.3.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from wandb) (78.1.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.12/site-packages (from wandb) (4.13.2)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.12/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ultralytics wandb\n",
    "!pip install dotenv\n",
    "!pip install shapely\n",
    "!pip install wandb opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab02345-a3f0-424f-9630-40700ac65d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import wandb\n",
    "from ultralytics import YOLO\n",
    "from tqdm.notebook import tqdm\n",
    "from shapely.geometry import box, MultiPolygon\n",
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from typing import Dict, List, Tuple\n",
    "import traceback\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a3cd17-1d51-4292-bc75-36d17d218d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONDict(\"/home/jovyan/.config/Ultralytics/settings.json\"):\n",
      "{\n",
      "  \"settings_version\": \"0.0.6\",\n",
      "  \"datasets_dir\": \"/home/jovyan/DSPRO2/M-AI-ZE-Maize-diseases-detection/notebooks/datasets\",\n",
      "  \"weights_dir\": \"weights\",\n",
      "  \"runs_dir\": \"runs\",\n",
      "  \"uuid\": \"8a115bbf5049f0fe55cf2ccd8be54ca8bfded6b963fd272724a959bb525556d2\",\n",
      "  \"sync\": true,\n",
      "  \"api_key\": \"\",\n",
      "  \"openai_api_key\": \"\",\n",
      "  \"clearml\": true,\n",
      "  \"comet\": true,\n",
      "  \"dvc\": true,\n",
      "  \"hub\": true,\n",
      "  \"mlflow\": true,\n",
      "  \"neptune\": true,\n",
      "  \"raytune\": true,\n",
      "  \"tensorboard\": false,\n",
      "  \"wandb\": true,\n",
      "  \"vscode_msg\": true,\n",
      "  \"openvino_msg\": true\n",
      "}\n",
      "💡 Learn more about Ultralytics Settings at https://docs.ultralytics.com/quickstart/#ultralytics-settings\n"
     ]
    }
   ],
   "source": [
    "!yolo settings wandb=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fefa102-b160-42c1-b14a-474ce0149f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WANDB_API_KEY: [69ca...]\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "print(f\"WANDB_API_KEY: [{wandb_api_key[:4]}...]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7945424-eadb-4480-af0c-37eb29d3c99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrueedi-tobias\u001b[0m (\u001b[33mrueedi-tobias-hochschule-luzern\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=wandb_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c89f480-b2c4-43fa-90a5-09446cfd786e",
   "metadata": {},
   "source": [
    "## Get Data and set Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "953504ea-b0d4-483a-927f-1472d9511ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = [8, 16, 32]\n",
    "DEFAULT_EPOCHS = 40\n",
    "DEFAULT_KFOLDS = 5\n",
    "BASE_PATH = Path(\"/exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits\")\n",
    "MODEL_WEIGHTS = {\"n\": \"yolo11n.pt\", \"m\": \"yolo11m.pt\", \"l\": \"yolo11l.pt\"}\n",
    "SUBTYPES = [\"boom\", \"drone\", \"handheld\"]\n",
    "IMG_SIZE  = 640\n",
    "TRAIN_PROJECT_PREFIX = \"maize_disease_detection_train\"\n",
    "EVAL_PROJECT_PREFIX  = \"maize_disease_detection_eval\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a35ba30-d194-4078-9cda-185508c53ca3",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "915ebfe1-f1dd-4c16-8c9f-c0331803b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_raad(pred_boxes, true_boxes, img_w=IMG_SIZE, img_h=IMG_SIZE,\n",
    "                   epsilon=1e-6, normalize=True):\n",
    "    if not pred_boxes and not true_boxes:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    if not pred_boxes:\n",
    "        true_area = sum((b[2]-b[0])*(b[3]-b[1]) for b in true_boxes)\n",
    "        return 1.0, 0.0, true_area\n",
    "    if not true_boxes:\n",
    "        pred_area = sum((b[2]-b[0])*(b[3]-b[1]) for b in pred_boxes)\n",
    "        return 1.0, pred_area, 0.0\n",
    "\n",
    "    if normalize:\n",
    "        pred_boxes = [[b[0]*img_w, b[1]*img_h, b[2]*img_w, b[3]*img_h] for b in pred_boxes]\n",
    "        true_boxes = [[b[0]*img_w, b[1]*img_h, b[2]*img_w, b[3]*img_h] for b in true_boxes]\n",
    "\n",
    "    pred_poly = MultiPolygon([box(*b) for b in pred_boxes]).buffer(0)\n",
    "    true_poly = MultiPolygon([box(*b) for b in true_boxes]).buffer(0)\n",
    "\n",
    "    pred_area = pred_poly.area\n",
    "    true_area = true_poly.area\n",
    "    raad = abs(pred_area - true_area) / max(true_area, epsilon)\n",
    "    return raad, pred_area, true_area\n",
    "\n",
    "\n",
    "def load_bbox_csv(csv_path: Path) -> Dict[str, List[Tuple[int,int,int,int]]]:\n",
    "    df = pd.read_csv(csv_path, header=None, skiprows=1)\n",
    "    out = {}\n",
    "    for _, row in df.iterrows():\n",
    "        out.setdefault(row[0], []).append(tuple(map(int, row[1:5])))\n",
    "    return out\n",
    "\n",
    "\n",
    "def suppress_yolo_logging():\n",
    "    \"\"\"Suppress the YOLO logging temporarily.\"\"\"\n",
    "    logger = logging.getLogger(\"ultralytics\")\n",
    "    original_level = logger.level\n",
    "    logger.setLevel(logging.ERROR)\n",
    "    return logger, original_level\n",
    "\n",
    "def restore_yolo_logging(logger, original_level):\n",
    "    \"\"\"Restore the YOLO logging to its original level.\"\"\"\n",
    "    logger.setLevel(original_level)\n",
    "\n",
    "def _make_sid02_subset(root: Path, subtype: str) -> Path:\n",
    "    \"\"\"\n",
    "    Creates subfolder for split SID02, because Yolo cant use subfolder.\n",
    "    Example ../train/boom need to be ../train \n",
    "    Therefore a temporary Folder gets created.\n",
    "    \"\"\"\n",
    "    tmp = root.parent / f\"{root.name}_{subtype}\"\n",
    "    if tmp.exists():\n",
    "        return tmp\n",
    "\n",
    "    for p in (\"images\", \"labels\"):\n",
    "        for split in (\"train\", \"val\"):\n",
    "            (tmp / p / split).mkdir(parents=True, exist_ok=True)\n",
    "    (tmp / \"images\" / \"test\").symlink_to(root / \"images\" / \"test\")\n",
    "    (tmp / \"labels\" / \"test\").symlink_to(root / \"labels\" / \"test\")\n",
    "\n",
    "    for phase in (\"train\", \"val\"):\n",
    "        lbl_src_root = root / \"labels\" / phase / subtype\n",
    "        img_src_root = root / \"images\" / phase\n",
    "        for lbl in lbl_src_root.glob(\"*.txt\"):\n",
    "            shutil.copy(lbl, tmp / \"labels\" / phase / lbl.name)\n",
    "            img_src = img_src_root / f\"{lbl.stem}.jpg\"\n",
    "            if img_src.exists():\n",
    "                (tmp / \"images\" / phase / img_src.name).symlink_to(img_src)\n",
    "\n",
    "    yaml_dict = {\n",
    "        \"train\": str(tmp / \"images\" / \"train\"),\n",
    "        \"val\":   str(tmp / \"images\" / \"val\"),\n",
    "        \"test\":  str(tmp / \"images\" / \"test\"),\n",
    "        \"nc\": 1,\n",
    "        \"names\": [\"lesion\"],\n",
    "    }\n",
    "    (tmp / \"data.yaml\").write_text(yaml.safe_dump(yaml_dict))\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2838ed3-e8af-4f4d-a8ec-2815249d4fba",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "045aa155-9561-40b0-9ace-ae7b75484bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        model_size=\"n\",    \n",
    "        split=\"SID01\",         \n",
    "        subtype=None,           \n",
    "        fold_id=None,            \n",
    "        epochs=10,\n",
    "        batch=16,\n",
    "        lr=0.01,\n",
    "        project = \"maize_disease_detection\",\n",
    "        run_name = \"not_set\"):\n",
    "\n",
    "    split_root = BASE_PATH / split\n",
    "\n",
    "\n",
    "    if split == \"SID02\" and subtype:\n",
    "        split_root = _make_sid02_subset(split_root, subtype)\n",
    "\n",
    "    if split == \"SID03\" and fold_id is not None:\n",
    "        split_root = split_root.parent / f\"{split}_kfold\" / f\"fold{fold_id}\"\n",
    "\n",
    "    dataset_yaml = split_root / \"data.yaml\"\n",
    "    if not dataset_yaml.exists():\n",
    "        raise FileNotFoundError(f\"YAML nicht gefunden: {dataset_yaml}\")\n",
    "\n",
    "    model_file = MODEL_WEIGHTS[model_size]\n",
    "\n",
    "    try:\n",
    "        model = YOLO(model_file)\n",
    "        results = model.train(\n",
    "            data=str(dataset_yaml),\n",
    "            epochs=epochs,\n",
    "            imgsz=IMG_SIZE,\n",
    "            lr0=lr,\n",
    "            batch=batch,\n",
    "            name=run_name,\n",
    "            project=project,\n",
    "            exist_ok=True\n",
    "        )\n",
    "\n",
    "        ckpt_dir = Path(\"runs\") / \"detect\" / run_name / \"weights\"\n",
    "        weights_path = next((ckpt_dir / f).as_posix() for f in (\"best.pt\", \"last.pt\") if (ckpt_dir / f).exists())\n",
    "\n",
    "        if wandb.run is not None:\n",
    "            wandb.finish()\n",
    "\n",
    "        cfg = dict(model=model_file, split=split, subtype=subtype,\n",
    "                   fold_id=fold_id, epochs=epochs, batch=batch,\n",
    "                   lr=lr, weights_path=weights_path)\n",
    "        wb = wandb.init(project=project,\n",
    "                        name=run_name, config=cfg, reinit=True)\n",
    "\n",
    "        mAP50     = results.results_dict.get(\"metrics/mAP50\", 0)\n",
    "        mAP50_95  = results.results_dict.get(\"metrics/mAP50-95\", 0)\n",
    "        wb.log({\"mAP50\": mAP50, \"mAP50-95\": mAP50_95})\n",
    "\n",
    "        val_img_dir = split_root / \"images\" / \"val\"\n",
    "        for i, img_file in enumerate(list(val_img_dir.glob(\"*.jpg\"))[:5]):\n",
    "            pred = model.predict(str(img_file), conf=0.25)[0]\n",
    "            img = cv2.cvtColor(cv2.imread(str(img_file)), cv2.COLOR_BGR2RGB)\n",
    "            for b in pred.boxes:\n",
    "                x1, y1, x2, y2 = map(int, b.xyxy[0])\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            wb.log({f\"val_image_{i}\": wandb.Image(img, caption=img_file.name)})\n",
    "\n",
    "        wb.finish()\n",
    "        return weights_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Training Error:\", e)\n",
    "        traceback.print_exc()\n",
    "        return MODEL_WEIGHTS[model_size] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b1ea1a-45b3-4a04-8552-b2cb4a2944f0",
   "metadata": {},
   "source": [
    "## Evaluate RAAD on Testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2080b9f0-1991-41f5-9824-35436c7273c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test_raad(model_path, split=\"SID01\", split_root=None, project=\"maize_disease_detection_eval\", run_name=None):\n",
    "    TARGET_SIZE = (640, 640)\n",
    "    \n",
    "    if split_root is None:\n",
    "        split_root = BASE_PATH / split\n",
    "    else:\n",
    "        split_root = Path(split_root)\n",
    "\n",
    "    test_img_dir = split_root / \"images\" / \"test\"\n",
    "    test_csv_path = split_root / \"labels\" / \"test\" / \"bboxes_test.csv\"\n",
    "\n",
    "    if not test_csv_path.exists():\n",
    "        raise FileNotFoundError(f\"Missing: {test_csv_path}\")\n",
    "    if not test_img_dir.exists():\n",
    "        raise FileNotFoundError(f\"Missing: {test_img_dir}\")\n",
    "\n",
    "    bounding_boxes = load_bbox_csv(test_csv_path)\n",
    "    model_name = Path(model_path).stem\n",
    "\n",
    "    run = wandb.init(\n",
    "        project=project,\n",
    "        name=run_name or f\"test_eval_{Path(model_path).stem}_{split_root.name}\",        \n",
    "        config={\"model_path\": str(model_path), \"split\": split_root.name},\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        model = YOLO(model_path)\n",
    "\n",
    "        results = {\n",
    "            \"image\": [],\n",
    "            \"raad\": [],\n",
    "            \"pred_area\": [],\n",
    "            \"true_area\": [],\n",
    "            \"prediction_count\": [],\n",
    "            \"truth_count\": [],\n",
    "        }\n",
    "\n",
    "        test_imgs = sorted([f for f in os.listdir(test_img_dir) if f.endswith(('.jpg', '.png'))])\n",
    "        for img_file in tqdm(test_imgs, desc=f\"Evaluating {split_root.name}\"):\n",
    "            img_path = test_img_dir / img_file\n",
    "\n",
    "            if img_file not in bounding_boxes:\n",
    "                print(f\"[!] Missing GT: {img_file}\")\n",
    "                continue\n",
    "\n",
    "            img = cv2.imread(str(img_path))\n",
    "            h, w = img.shape[:2]\n",
    "\n",
    "            logger, original_level = suppress_yolo_logging()\n",
    "            try:\n",
    "                preds = model.predict(str(img_path), save=False)[0]\n",
    "            finally:\n",
    "                restore_yolo_logging(logger, original_level)\n",
    "            \n",
    "            pred_boxes = preds.boxes.xyxy.cpu().numpy().tolist()\n",
    "            true_boxes = bounding_boxes[img_file]\n",
    "\n",
    "            raad, pred_area, true_area = calculate_raad(pred_boxes, true_boxes, w, h, normalize=False)\n",
    "\n",
    "            results[\"image\"].append(img_file)\n",
    "            results[\"raad\"].append(raad)\n",
    "            results[\"pred_area\"].append(pred_area)\n",
    "            results[\"true_area\"].append(true_area)\n",
    "            results[\"prediction_count\"].append(len(pred_boxes))\n",
    "            results[\"truth_count\"].append(len(true_boxes))\n",
    "\n",
    "        df = pd.DataFrame(results)\n",
    "        avg_raad = df[\"raad\"].mean()\n",
    "\n",
    "        print(f\"Average RAAD on {split_root.name}: {avg_raad:.4f}\")\n",
    "        avg_pred_area = df[\"pred_area\"].mean()\n",
    "        avg_true_area = df[\"true_area\"].mean()\n",
    "        avg_pred_count = df[\"prediction_count\"].mean()\n",
    "        avg_truth_count = df[\"truth_count\"].mean()\n",
    "        avg_count_ratio = avg_pred_count / max(avg_truth_count, 1e-6)\n",
    "        \n",
    "        run.log({\n",
    "            \"avg_raad\": avg_raad,\n",
    "            \"avg_pred_area\": avg_pred_area,\n",
    "            \"avg_true_area\": avg_true_area,\n",
    "            \"avg_pred_count\": avg_pred_count,\n",
    "            \"avg_truth_count\": avg_truth_count,\n",
    "            \"avg_count_ratio\": avg_count_ratio\n",
    "        })\n",
    "\n",
    "        table = wandb.Table(columns=[\"image\", \"raad\", \"pred_area\", \"true_area\", \n",
    "                                     \"prediction_count\", \"truth_count\", \"count_ratio\"])\n",
    "        for _, row in df.iterrows():\n",
    "            count_ratio = row[\"prediction_count\"] / max(row[\"truth_count\"], 1e-6)\n",
    "            table.add_data(row[\"image\"], row[\"raad\"], row[\"pred_area\"], row[\"true_area\"],\n",
    "                           row[\"prediction_count\"], row[\"truth_count\"], count_ratio)\n",
    "\n",
    "        \n",
    "        run.log({\"per_image_results\": table})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Evaluation error: {e}\")\n",
    "        run.finish()\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b394b5ee-680b-4b34-8925-9ac4b32733e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kfold_yamls(split_dir: Path, k: int = 5):\n",
    "    assert split_dir.name.startswith(\"SID03\"), \"Only for SID03 Split.\"\n",
    "\n",
    "    train_img_dir = split_dir / \"images\" / \"train\"\n",
    "    all_imgs = list(train_img_dir.glob(\"*.jpg\"))\n",
    "    random.shuffle(all_imgs)\n",
    "\n",
    "    fold_size = len(all_imgs) // k\n",
    "    fold_root = split_dir.parent / f\"{split_dir.name}_kfold\"\n",
    "    fold_root.mkdir(exist_ok=True)\n",
    "\n",
    "    for fold in range(k):\n",
    "        fold_dir = fold_root / f\"fold{fold}\"\n",
    "\n",
    "        for phase in [\"train\", \"val\", \"test\"]:\n",
    "            (fold_dir / \"images\" / phase).mkdir(parents=True, exist_ok=True)\n",
    "            (fold_dir / \"labels\" / phase).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        val_set = set(all_imgs[fold * fold_size : (fold + 1) * fold_size])\n",
    "\n",
    "        for img_path in all_imgs:\n",
    "            phase = \"val\" if img_path in val_set else \"train\"\n",
    "            shutil.copy(img_path, fold_dir / \"images\" / phase / img_path.name)\n",
    "\n",
    "            label_found = False\n",
    "            for subtype in SUBTYPES:\n",
    "                lbl_src = split_dir / \"labels\" / \"train\" / subtype / f\"{img_path.stem}.txt\"\n",
    "                if lbl_src.exists():\n",
    "                    shutil.copy(lbl_src, fold_dir / \"labels\" / phase / lbl_src.name)\n",
    "                    label_found = True\n",
    "                    break\n",
    "            if not label_found:\n",
    "                print(f\"[!] Keine Labeldatei für: {img_path.name}\")\n",
    "\n",
    "        for phase in [\"images\", \"labels\"]:\n",
    "            src = split_dir / phase / \"test\"\n",
    "            dst = fold_dir / phase / \"test\"\n",
    "            if not dst.exists():\n",
    "                dst.symlink_to(src)\n",
    "\n",
    "        yaml_dict = {\n",
    "            \"train\": str((fold_dir / \"images/train\").resolve()),\n",
    "            \"val\": str((fold_dir / \"images/val\").resolve()),\n",
    "            \"test\": str((fold_dir / \"images/test\").resolve()),\n",
    "            \"nc\": 1,\n",
    "            \"names\": [\"lesion\"]\n",
    "        }\n",
    "        with open(fold_dir / \"data.yaml\", \"w\") as f:\n",
    "            yaml.safe_dump(yaml_dict, f)\n",
    "\n",
    "\n",
    "        csv_src = split_dir / \"labels\" / \"test\" / \"bboxes_test.csv\"\n",
    "        csv_dst = fold_dir / \"labels\" / \"test\" / \"bboxes_test.csv\"\n",
    "        if csv_src.exists():\n",
    "            shutil.copy(csv_src, csv_dst)\n",
    "        else:\n",
    "            print(f\"[Didnt found bboxes_test.csv: {csv_src}\")\n",
    "        \n",
    "        print(f\"Fold {fold} created: {fold_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d354d3b3-4747-419e-bbb5-b2aec46b1d7a",
   "metadata": {},
   "source": [
    "# Start Train and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2788797-08c1-40fd-872f-d8a739c4afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_and_eval(\n",
    "    splits=[\"SID01\", \"SID02\"],            \n",
    "    models=[\"n\", \"m\", \"l\"],                \n",
    "    batches=[16, 32],                     \n",
    "    epochs=40,\n",
    "    lr=0.01,\n",
    "    train_project=\"maize_train\",\n",
    "    eval_project=\"maize_eval\",\n",
    "    sid02_subtypes=[None, \"drone\", \"boom\", \"handheld\"],  \n",
    "    sid03_folds=None,                     \n",
    "    device=\"0\"\n",
    "):\n",
    "    for split in splits:\n",
    "        if split == \"SID01\":\n",
    "            for model in models:\n",
    "                for batch in batches:\n",
    "                    run_name = f\"yolo11{model}_{split}_e{epochs}_b{batch}\"\n",
    "                    weights = train_model(\n",
    "                        model_size=model,\n",
    "                        split=split,\n",
    "                        epochs=epochs,\n",
    "                        batch=batch,\n",
    "                        lr=lr,\n",
    "                        project=train_project,\n",
    "                        run_name = run_name\n",
    "                    )\n",
    "                    evaluate_test_raad(\n",
    "                        model_path=weights,\n",
    "                        split=split,\n",
    "                        split_root=BASE_PATH / split,\n",
    "                        project =  eval_project,\n",
    "                        run_name=run_name\n",
    "                    )\n",
    "\n",
    "        elif split == \"SID02\":\n",
    "            for subtype in sid02_subtypes:\n",
    "                subtype_tag = subtype if subtype else \"all\"\n",
    "                subset_root = _make_sid02_subset(BASE_PATH / \"SID02\", subtype) if subtype else BASE_PATH / \"SID02\"\n",
    "\n",
    "                for model in models:\n",
    "                    for batch in batches:\n",
    "                        run_name = f\"yolo11{model}_{split}_{subtype}_e{epochs}_b{batch}\"\n",
    "                        weights = train_model(\n",
    "                            model_size=model,\n",
    "                            split=\"SID02\",\n",
    "                            subtype=subtype,\n",
    "                            epochs=epochs,\n",
    "                            batch=batch,\n",
    "                            lr=lr,\n",
    "                            project=train_project,\n",
    "                            run_name=run_name\n",
    "                        )\n",
    "                        evaluate_test_raad(\n",
    "                            model_path=weights,\n",
    "                            split=\"SID02\",\n",
    "                            split_root=subset_root,\n",
    "                            project =  eval_project,\n",
    "                            run_name=run_name\n",
    "                        )\n",
    "\n",
    "        elif split == \"SID03\":\n",
    "            sid03_kfold_root = BASE_PATH / \"SID03_kfold\"\n",
    "            if not sid03_kfold_root.exists():\n",
    "                print(\"SID03_kfold not found – generate K-Folds...\")\n",
    "                generate_kfold_yamls(BASE_PATH / \"SID03\", k=5)\n",
    "        \n",
    "            folds = sid03_folds if sid03_folds else [None]\n",
    "\n",
    "            for fold in folds:\n",
    "                for model in models:\n",
    "                    for batch in batches:\n",
    "                        run_name = f\"yolo11{model}_{split}_e{epochs}_b{batch}\"\n",
    "                        weights = train_model(\n",
    "                            model_size=model,\n",
    "                            split=\"SID03\",\n",
    "                            fold_id=fold,\n",
    "                            epochs=epochs,\n",
    "                            batch=batch,\n",
    "                            lr=lr,\n",
    "                            project=train_project,\n",
    "                            run_name=run_name\n",
    "                        )\n",
    "                        fold_path = (BASE_PATH / \"SID03_kfold\" / f\"fold{fold}\") if fold is not None else BASE_PATH / \"SID03\"\n",
    "                        sid03_test_root = BASE_PATH / \"SID03\"\n",
    "                        evaluate_test_raad(\n",
    "                            model_path=weights,\n",
    "                            split=\"SID03\",\n",
    "                            split_root=sid03_test_root,\n",
    "                            project=eval_project,\n",
    "                            run_name=run_name\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabfa73e-039e-4526-a87c-30b924caf5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.146 🚀 Python-3.12.10 torch-2.7.0+cu126 CUDA:0 (NVIDIA A16, 14891MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=40, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11n_SID01_e40_b8, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=maize_disease_detection_train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=maize_disease_detection_train/yolo11n_SID01_e40_b8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/DSPRO2/M-AI-ZE-Maize-diseases-detection/notebooks/wandb/run-20250529_130818-4ao8erdd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_disease_detection_train/runs/4ao8erdd' target=\"_blank\">yolo11n_SID01_e40_b8</a></strong> to <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_disease_detection_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_disease_detection_train' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_disease_detection_train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_disease_detection_train/runs/4ao8erdd' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_disease_detection_train/runs/4ao8erdd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2114.1±601.4 MB/s, size: 59.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/labels/train.cache... 10858 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10858/10858 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1712.0±777.7 MB/s, size: 56.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/labels/val.cache... 1357 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1357/1357 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to maize_disease_detection_train/yolo11n_SID01_e40_b8/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mmaize_disease_detection_train/yolo11n_SID01_e40_b8\u001b[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/40      1.38G      2.266      2.346      1.576          8        640: 100%|██████████| 1358/1358 [03:18<00:00,  6.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 85/85 [00:11<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.426      0.362      0.334      0.131\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/40      1.93G      2.113      1.932      1.478          5        640: 100%|██████████| 1358/1358 [03:08<00:00,  7.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 85/85 [00:10<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.445      0.393      0.355      0.144\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/40      1.94G       2.07      1.868      1.459         14        640: 100%|██████████| 1358/1358 [03:06<00:00,  7.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 85/85 [00:10<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.498        0.4        0.4      0.169\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/40      1.94G      2.035       1.81      1.437         26        640: 100%|██████████| 1358/1358 [03:05<00:00,  7.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 85/85 [00:10<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.515      0.407      0.414      0.178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/40      1.94G      1.997      1.762      1.418         31        640: 100%|██████████| 1358/1358 [03:06<00:00,  7.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 85/85 [00:10<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.525      0.432      0.437      0.198\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/40      1.94G      1.982      1.741      1.406         24        640: 100%|██████████| 1358/1358 [03:06<00:00,  7.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 85/85 [00:10<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.549      0.445      0.458      0.211\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/40      1.94G      1.957      1.708      1.391         22        640: 100%|██████████| 1358/1358 [03:06<00:00,  7.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 85/85 [00:10<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.542      0.458      0.462       0.21\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/40      1.94G      1.947      1.693      1.382         17        640: 100%|██████████| 1358/1358 [03:05<00:00,  7.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 85/85 [00:10<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.565      0.467      0.487      0.227\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/40      1.95G      1.937      1.666       1.37         12        640: 100%|██████████| 1358/1358 [03:05<00:00,  7.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 85/85 [00:10<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668       0.58       0.47      0.497      0.229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/40      1.95G      1.923      1.643      1.365         16        640: 100%|██████████| 1358/1358 [03:06<00:00,  7.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 85/85 [00:10<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.575      0.472      0.496       0.23\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/40      1.95G      1.919      1.643      1.358          6        640: 100%|██████████| 1358/1358 [03:05<00:00,  7.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 85/85 [00:10<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.568      0.455       0.48      0.226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/40      1.95G      1.897      1.624      1.348         17        640: 100%|██████████| 1358/1358 [03:06<00:00,  7.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 85/85 [00:10<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.573      0.461      0.488      0.225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/40      1.95G      1.895      1.602      1.348         32        640: 100%|██████████| 1358/1358 [03:06<00:00,  7.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 85/85 [00:10<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.583       0.48      0.513      0.241\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/40      1.95G      1.889        1.6      1.343         31        640: 100%|██████████| 1358/1358 [03:05<00:00,  7.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 85/85 [00:10<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.578      0.488      0.514      0.245\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/40      1.95G      1.881      1.585      1.337         29        640: 100%|██████████| 1358/1358 [03:05<00:00,  7.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 85/85 [00:10<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.591      0.491      0.526      0.247\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/40      1.95G      1.878      1.575      1.332         21        640: 100%|██████████| 1358/1358 [03:05<00:00,  7.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 85/85 [00:10<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.595      0.488      0.526      0.249\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/40      1.95G      1.867       1.56      1.324          8        640: 100%|██████████| 1358/1358 [03:05<00:00,  7.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 85/85 [00:10<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.605      0.499      0.534      0.253\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/40      1.95G      1.865      1.554      1.323         48        640: 100%|██████████| 1358/1358 [03:05<00:00,  7.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 85/85 [00:10<00:00,  7.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.598      0.505      0.538      0.255\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/40      1.95G       1.86      1.545      1.319          2        640: 100%|██████████| 1358/1358 [03:06<00:00,  7.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 85/85 [00:10<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.606      0.498      0.539      0.259\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/40      1.95G      1.855      1.534      1.317          8        640: 100%|██████████| 1358/1358 [03:05<00:00,  7.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 85/85 [00:10<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.599      0.502      0.536      0.259\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/40      1.95G      1.844      1.524      1.312         52        640:  61%|██████    | 826/1358 [01:52<01:13,  7.21it/s]"
     ]
    }
   ],
   "source": [
    "run_training_and_eval(\n",
    "    splits=[\"SID01\", \"SID02\", \"SID03\"],\n",
    "    models=[\"n\",\"m\",\"l\"],\n",
    "    batches=[8, 16],\n",
    "    epochs=40,\n",
    "    train_project=TRAIN_PROJECT_PREFIX,\n",
    "    eval_project=EVAL_PROJECT_PREFIX,\n",
    "    sid02_subtypes=[\"boom\", \"drone\",\"handheld\"],\n",
    "    sid03_folds=[0,2,3],\n",
    "    device=\"0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a97df89-f043-47ff-a815-0cdf950232c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
