{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d11444d-4a37-4242-a2dd-64a83c721bf8",
   "metadata": {},
   "source": [
    "# YOLOv11 Model Training and Evaluation for Maize Disease Detection\n",
    "\n",
    "This notebook provides a complete pipeline for training and evaluating YOLOv11 object detection models on the **maize lesion dataset**, structured across multiple dataset splits: `SID01`, `SID02`, and `SID03`.\n",
    "\n",
    "Key features of this pipeline include:\n",
    "\n",
    "- **Automated training** across different YOLO variants (`n`, `m`, `l`), batch sizes, and splits.\n",
    "- Support for:\n",
    "  - `SID02` subtype-specific training (`boom`, `drone`, `handheld`)\n",
    "  - `SID03` K-Fold cross-validation.\n",
    "- **Custom evaluation using the RAAD metric** (Relative Affected Area Difference), assessing bounding box area agreement between predictions and ground truth.\n",
    "- **Integration with Weights & Biases (wandb)** for:\n",
    "  - Tracking training runs and hyperparameters.\n",
    "  - Logging test metrics and qualitative predictions.\n",
    "  - Uploading per-image evaluation tables and **collage visualizations** for best/worst cases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd99517-1d1a-42f8-acd9-8b7f78c2cd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /opt/conda/lib/python3.12/site-packages (8.3.150)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.12/site-packages (0.20.1)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (3.10.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.7.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (0.22.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.12/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.12/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from wandb) (24.2)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.12/site-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (4.25.6)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.29.1)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.12/site-packages (from wandb) (1.3.6)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in /opt/conda/lib/python3.12/site-packages (from wandb) (4.13.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (78.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Requirement already satisfied: dotenv in /opt/conda/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.12/site-packages (from dotenv) (1.1.0)\n",
      "Requirement already satisfied: shapely in /opt/conda/lib/python3.12/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.12/site-packages (from shapely) (1.26.4)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.12/site-packages (0.20.1)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.12/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from wandb) (24.2)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.12/site-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (4.25.6)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.12/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.29.1)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.12/site-packages (from wandb) (1.3.6)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in /opt/conda/lib/python3.12/site-packages (from wandb) (4.13.2)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.12/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ultralytics wandb\n",
    "!pip install dotenv\n",
    "!pip install shapely\n",
    "!pip install wandb opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab02345-a3f0-424f-9630-40700ac65d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import wandb\n",
    "from ultralytics import YOLO\n",
    "from tqdm.notebook import tqdm\n",
    "from shapely.geometry import box, MultiPolygon\n",
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from typing import Dict, List, Tuple\n",
    "import traceback\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a3cd17-1d51-4292-bc75-36d17d218d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONDict(\"/home/jovyan/.config/Ultralytics/settings.json\"):\n",
      "{\n",
      "  \"settings_version\": \"0.0.6\",\n",
      "  \"datasets_dir\": \"/home/jovyan/DSPRO2/M-AI-ZE-Maize-diseases-detection/notebooks/datasets\",\n",
      "  \"weights_dir\": \"weights\",\n",
      "  \"runs_dir\": \"runs\",\n",
      "  \"uuid\": \"8a115bbf5049f0fe55cf2ccd8be54ca8bfded6b963fd272724a959bb525556d2\",\n",
      "  \"sync\": true,\n",
      "  \"api_key\": \"\",\n",
      "  \"openai_api_key\": \"\",\n",
      "  \"clearml\": true,\n",
      "  \"comet\": true,\n",
      "  \"dvc\": true,\n",
      "  \"hub\": true,\n",
      "  \"mlflow\": true,\n",
      "  \"neptune\": true,\n",
      "  \"raytune\": true,\n",
      "  \"tensorboard\": false,\n",
      "  \"wandb\": true,\n",
      "  \"vscode_msg\": true,\n",
      "  \"openvino_msg\": true\n",
      "}\n",
      "ðŸ’¡ Learn more about Ultralytics Settings at https://docs.ultralytics.com/quickstart/#ultralytics-settings\n"
     ]
    }
   ],
   "source": [
    "!yolo settings wandb=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fefa102-b160-42c1-b14a-474ce0149f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WANDB_API_KEY: [69ca...]\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "print(f\"WANDB_API_KEY: [{wandb_api_key[:4]}...]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7945424-eadb-4480-af0c-37eb29d3c99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrueedi-tobias\u001b[0m (\u001b[33mrueedi-tobias-hochschule-luzern\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=wandb_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c89f480-b2c4-43fa-90a5-09446cfd786e",
   "metadata": {},
   "source": [
    "## Get Data and set Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "953504ea-b0d4-483a-927f-1472d9511ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = [8, 16, 32]\n",
    "DEFAULT_EPOCHS = 40\n",
    "DEFAULT_KFOLDS = 5\n",
    "BASE_PATH = Path(\"/exchange/dspro2/M-AI-ZE/data/adjusted/1.2/splits\")\n",
    "MODEL_WEIGHTS = {\"s\": \"yolo11s.pt\", \"n\": \"yolo11n.pt\", \"m\": \"yolo11m.pt\", \"l\": \"yolo11l.pt\"}\n",
    "SUBTYPES = [\"boom\", \"drone\", \"handheld\"]\n",
    "IMG_SIZE  = 640\n",
    "TRAIN_PROJECT_PREFIX = \"V1_2-maize_disease_detection_train\"\n",
    "EVAL_PROJECT_PREFIX  = \"V1_2-maize_disease_detection_eval\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a35ba30-d194-4078-9cda-185508c53ca3",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "915ebfe1-f1dd-4c16-8c9f-c0331803b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_raad(pred_boxes, true_boxes, img_w=IMG_SIZE, img_h=IMG_SIZE,\n",
    "                   epsilon=1e-6, normalize=True):\n",
    "    if not pred_boxes and not true_boxes:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    if not pred_boxes:\n",
    "        true_area = sum((b[2]-b[0])*(b[3]-b[1]) for b in true_boxes)\n",
    "        return 1.0, 0.0, true_area\n",
    "    if not true_boxes:\n",
    "        pred_area = sum((b[2]-b[0])*(b[3]-b[1]) for b in pred_boxes)\n",
    "        return 1.0, pred_area, 0.0\n",
    "\n",
    "    if normalize:\n",
    "        pred_boxes = [[b[0]*img_w, b[1]*img_h, b[2]*img_w, b[3]*img_h] for b in pred_boxes]\n",
    "        true_boxes = [[b[0]*img_w, b[1]*img_h, b[2]*img_w, b[3]*img_h] for b in true_boxes]\n",
    "\n",
    "    pred_poly = MultiPolygon([box(*b) for b in pred_boxes]).buffer(0)\n",
    "    true_poly = MultiPolygon([box(*b) for b in true_boxes]).buffer(0)\n",
    "\n",
    "    pred_area = pred_poly.area\n",
    "    true_area = true_poly.area\n",
    "    raad = abs(pred_area - true_area) / max(true_area, epsilon)\n",
    "    return raad, pred_area, true_area\n",
    "\n",
    "\n",
    "def load_bbox_csv(csv_path: Path) -> Dict[str, List[Tuple[int,int,int,int]]]:\n",
    "    df = pd.read_csv(csv_path, header=None, skiprows=1)\n",
    "    out = {}\n",
    "    for _, row in df.iterrows():\n",
    "        out.setdefault(row[0], []).append(tuple(map(int, row[1:5])))\n",
    "    return out\n",
    "\n",
    "\n",
    "def suppress_yolo_logging():\n",
    "    \"\"\"Suppress the YOLO logging temporarily.\"\"\"\n",
    "    logger = logging.getLogger(\"ultralytics\")\n",
    "    original_level = logger.level\n",
    "    logger.setLevel(logging.ERROR)\n",
    "    return logger, original_level\n",
    "\n",
    "def restore_yolo_logging(logger, original_level):\n",
    "    \"\"\"Restore the YOLO logging to its original level.\"\"\"\n",
    "    logger.setLevel(original_level)\n",
    "\n",
    "def _make_sid02_subset(root: Path, subtype: str) -> Path:\n",
    "    \"\"\"\n",
    "    Creates subfolder for split SID02, because Yolo cant use subfolder.\n",
    "    Example ../train/boom need to be ../train \n",
    "    Therefore a temporary Folder gets created.\n",
    "    \"\"\"\n",
    "    tmp = root.parent / f\"{root.name}_{subtype}\"\n",
    "    if tmp.exists():\n",
    "        return tmp\n",
    "\n",
    "    for p in (\"images\", \"labels\"):\n",
    "        for split in (\"train\", \"val\"):\n",
    "            (tmp / p / split).mkdir(parents=True, exist_ok=True)\n",
    "    (tmp / \"images\" / \"test\").symlink_to(root / \"images\" / \"test\")\n",
    "    (tmp / \"labels\" / \"test\").symlink_to(root / \"labels\" / \"test\")\n",
    "\n",
    "    for phase in (\"train\", \"val\"):\n",
    "        lbl_src_root = root / \"labels\" / phase / subtype\n",
    "        img_src_root = root / \"images\" / phase\n",
    "        for lbl in lbl_src_root.glob(\"*.txt\"):\n",
    "            shutil.copy(lbl, tmp / \"labels\" / phase / lbl.name)\n",
    "            img_src = img_src_root / f\"{lbl.stem}.jpg\"\n",
    "            if img_src.exists():\n",
    "                (tmp / \"images\" / phase / img_src.name).symlink_to(img_src)\n",
    "\n",
    "    yaml_dict = {\n",
    "        \"train\": str(tmp / \"images\" / \"train\"),\n",
    "        \"val\":   str(tmp / \"images\" / \"val\"),\n",
    "        \"test\":  str(tmp / \"images\" / \"test\"),\n",
    "        \"nc\": 1,\n",
    "        \"names\": [\"lesion\"],\n",
    "    }\n",
    "    (tmp / \"data.yaml\").write_text(yaml.safe_dump(yaml_dict))\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2838ed3-e8af-4f4d-a8ec-2815249d4fba",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "045aa155-9561-40b0-9ace-ae7b75484bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        model_size=\"n\",    \n",
    "        split=\"SID01\",         \n",
    "        subtype=None,           \n",
    "        fold_id=None,            \n",
    "        epochs=10,\n",
    "        batch=16,\n",
    "        lr=0.01,\n",
    "        project = \"maize_disease_detection\",\n",
    "        run_name = \"not_set\"):\n",
    "\n",
    "    split_root = BASE_PATH / split\n",
    "\n",
    "\n",
    "    if split == \"SID02\" and subtype:\n",
    "        split_root = _make_sid02_subset(split_root, subtype)\n",
    "\n",
    "    if split == \"SID03\" and fold_id is not None:\n",
    "        split_root = split_root.parent / f\"{split}_kfold\" / f\"fold{fold_id}\"\n",
    "\n",
    "    dataset_yaml = split_root / \"data.yaml\"\n",
    "    if not dataset_yaml.exists():\n",
    "        raise FileNotFoundError(f\"YAML nicht gefunden: {dataset_yaml}\")\n",
    "\n",
    "    model_file = MODEL_WEIGHTS[model_size]\n",
    "\n",
    "    try:\n",
    "        model = YOLO(model_file)\n",
    "        results = model.train(\n",
    "            data=str(dataset_yaml),\n",
    "            epochs=epochs,\n",
    "            imgsz=IMG_SIZE,\n",
    "            lr0=lr,\n",
    "            batch=batch,\n",
    "            name=run_name,\n",
    "            project=project,\n",
    "            exist_ok=True\n",
    "        )\n",
    "\n",
    "        ckpt_dir = Path(\"runs\") / \"detect\" / run_name / \"weights\"\n",
    "        weights_path = next((ckpt_dir / f).as_posix() for f in (\"best.pt\", \"last.pt\") if (ckpt_dir / f).exists())\n",
    "\n",
    "        if wandb.run is not None:\n",
    "            wandb.finish()\n",
    "\n",
    "        cfg = dict(model=model_file, split=split, subtype=subtype,\n",
    "                   fold_id=fold_id, epochs=epochs, batch=batch,\n",
    "                   lr=lr, weights_path=weights_path)\n",
    "        wb = wandb.init(project=project,\n",
    "                        name=run_name, config=cfg, reinit=True)\n",
    "\n",
    "        mAP50     = results.results_dict.get(\"metrics/mAP50\", 0)\n",
    "        mAP50_95  = results.results_dict.get(\"metrics/mAP50-95\", 0)\n",
    "        wb.log({\"mAP50\": mAP50, \"mAP50-95\": mAP50_95})\n",
    "\n",
    "        val_img_dir = split_root / \"images\" / \"val\"\n",
    "        for i, img_file in enumerate(list(val_img_dir.glob(\"*.jpg\"))[:5]):\n",
    "            pred = model.predict(str(img_file), conf=0.25)[0]\n",
    "            img = cv2.cvtColor(cv2.imread(str(img_file)), cv2.COLOR_BGR2RGB)\n",
    "            for b in pred.boxes:\n",
    "                x1, y1, x2, y2 = map(int, b.xyxy[0])\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            wb.log({f\"val_image_{i}\": wandb.Image(img, caption=img_file.name)})\n",
    "\n",
    "        wb.finish()\n",
    "        return weights_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Training Error:\", e)\n",
    "        traceback.print_exc()\n",
    "        return MODEL_WEIGHTS[model_size] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b1ea1a-45b3-4a04-8552-b2cb4a2944f0",
   "metadata": {},
   "source": [
    "## Evaluate RAAD on Testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2080b9f0-1991-41f5-9824-35436c7273c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test_raad(model_path, split=\"SID01\", split_root=None, project=\"maize_disease_detection_eval\", run_name=None):\n",
    "    TARGET_SIZE = (640, 640)\n",
    "    \n",
    "    if split_root is None:\n",
    "        split_root = BASE_PATH / split\n",
    "    else:\n",
    "        split_root = Path(split_root)\n",
    "\n",
    "    test_img_dir = split_root / \"images\" / \"test\"\n",
    "    test_csv_path = split_root / \"labels\" / \"test\" / \"bboxes_test.csv\"\n",
    "\n",
    "    if not test_csv_path.exists():\n",
    "        raise FileNotFoundError(f\"Missing: {test_csv_path}\")\n",
    "    if not test_img_dir.exists():\n",
    "        raise FileNotFoundError(f\"Missing: {test_img_dir}\")\n",
    "\n",
    "    bounding_boxes = load_bbox_csv(test_csv_path)\n",
    "    model_name = Path(model_path).stem\n",
    "\n",
    "    run = wandb.init(\n",
    "        project=project,\n",
    "        name=run_name or f\"test_eval_{Path(model_path).stem}_{split_root.name}\",        \n",
    "        config={\"model_path\": str(model_path), \"split\": split_root.name},\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        model = YOLO(model_path)\n",
    "\n",
    "        results = {\n",
    "            \"image\": [],\n",
    "            \"raad\": [],\n",
    "            \"pred_area\": [],\n",
    "            \"true_area\": [],\n",
    "            \"prediction_count\": [],\n",
    "            \"truth_count\": [],\n",
    "            \"area_score\" : []\n",
    "        }\n",
    "\n",
    "        test_imgs = sorted([f for f in os.listdir(test_img_dir) if f.endswith(('.jpg', '.png'))])\n",
    "        for img_file in tqdm(test_imgs, desc=f\"Evaluating {split_root.name}\"):\n",
    "            img_path = test_img_dir / img_file\n",
    "\n",
    "            if img_file not in bounding_boxes:\n",
    "                print(f\"[!] Missing GT: {img_file}\")\n",
    "                continue\n",
    "\n",
    "            img = cv2.imread(str(img_path))\n",
    "            h, w = img.shape[:2]\n",
    "\n",
    "            logger, original_level = suppress_yolo_logging()\n",
    "            try:\n",
    "                preds = model.predict(str(img_path), save=False)[0]\n",
    "            finally:\n",
    "                restore_yolo_logging(logger, original_level)\n",
    "            \n",
    "            pred_boxes = preds.boxes.xyxy.cpu().numpy().tolist()\n",
    "            true_boxes = bounding_boxes[img_file]\n",
    "\n",
    "            raad, pred_area, true_area = calculate_raad(pred_boxes, true_boxes, w, h, normalize=False)\n",
    "            area_score = (pred_area / true_area) * 100\n",
    "\n",
    "            results[\"image\"].append(img_file)\n",
    "            results[\"raad\"].append(raad)\n",
    "            results[\"pred_area\"].append(pred_area)\n",
    "            results[\"true_area\"].append(true_area)\n",
    "            results[\"prediction_count\"].append(len(pred_boxes))\n",
    "            results[\"truth_count\"].append(len(true_boxes))\n",
    "            results[\"area_score\"].append(area_score)\n",
    "\n",
    "        df = pd.DataFrame(results)\n",
    "        avg_raad = df[\"raad\"].mean()\n",
    "        median_raad = df[\"raad\"].median()\n",
    "        max_raad = df[\"raad\"].max()\n",
    "        \n",
    "        avg_area_score = df[\"area_score\"].mean()\n",
    "        avg_pred_area = df[\"pred_area\"].mean()\n",
    "        avg_true_area = df[\"true_area\"].mean()\n",
    "        avg_pred_count = df[\"prediction_count\"].mean()\n",
    "        avg_truth_count = df[\"truth_count\"].mean()\n",
    "        avg_count_ratio = avg_pred_count / max(avg_truth_count, 1e-6)\n",
    "\n",
    "        val_result = model.val(data=str(split_root / \"data.yaml\"), imgsz=640)\n",
    "        mAP50 = val_result.results_dict.get(\"metrics/mAP50\", 0)\n",
    "        \n",
    "        run.log({\n",
    "            \"avg_raad\": avg_raad,\n",
    "            \"median_raad\": median_raad,\n",
    "            \"max_raad\" : max_raad,\n",
    "            \"avg_pred_area\": avg_pred_area,\n",
    "            \"avg_true_area\": avg_true_area,\n",
    "            \"avg_pred_count\": avg_pred_count,\n",
    "            \"avg_truth_count\": avg_truth_count,\n",
    "            \"avg_count_ratio\": avg_count_ratio,\n",
    "            \"avg_area_score\": avg_area_score,\n",
    "            \"mAP@0.5\": mAP50\n",
    "        })\n",
    "\n",
    "        print(\"test1\")\n",
    "\n",
    "        table = wandb.Table(columns=[\"image\", \"raad\", \"pred_area\", \"true_area\", \n",
    "                                     \"prediction_count\", \"truth_count\", \"count_ratio\", \"area_score\"])\n",
    "\n",
    "        print(\"test2\")\n",
    "        for _, row in df.iterrows():\n",
    "            count_ratio = row[\"prediction_count\"] / max(row[\"truth_count\"], 1e-6)\n",
    "            table.add_data(row[\"image\"], row[\"raad\"], row[\"pred_area\"], row[\"true_area\"],\n",
    "                           row[\"prediction_count\"], row[\"truth_count\"], count_ratio, row[\"area_score\"])\n",
    "\n",
    "        print(\"test3\")\n",
    "        run.log({\"per_image_results\": table})\n",
    "\n",
    "        run.finish()\n",
    "        return df, avg_raad\n",
    "    except Exception as e:\n",
    "        print(f\"Evaluation error: {e}\")\n",
    "        run.finish()\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b394b5ee-680b-4b34-8925-9ac4b32733e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kfold_yamls(split_dir: Path, k: int = 5):\n",
    "    assert split_dir.name.startswith(\"SID03\"), \"Only for SID03 Split.\"\n",
    "\n",
    "    train_img_dir = split_dir / \"images\" / \"train\"\n",
    "    all_imgs = list(train_img_dir.glob(\"*.jpg\"))\n",
    "    random.shuffle(all_imgs)\n",
    "\n",
    "    fold_size = len(all_imgs) // k\n",
    "    fold_root = split_dir.parent / f\"{split_dir.name}_kfold\"\n",
    "    fold_root.mkdir(exist_ok=True)\n",
    "\n",
    "    for fold in range(k):\n",
    "        fold_dir = fold_root / f\"fold{fold}\"\n",
    "\n",
    "        for phase in [\"train\", \"val\", \"test\"]:\n",
    "            (fold_dir / \"images\" / phase).mkdir(parents=True, exist_ok=True)\n",
    "            (fold_dir / \"labels\" / phase).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        val_set = set(all_imgs[fold * fold_size : (fold + 1) * fold_size])\n",
    "\n",
    "        for img_path in all_imgs:\n",
    "            phase = \"val\" if img_path in val_set else \"train\"\n",
    "            shutil.copy(img_path, fold_dir / \"images\" / phase / img_path.name)\n",
    "\n",
    "            label_found = False\n",
    "            for subtype in SUBTYPES:\n",
    "                lbl_src = split_dir / \"labels\" / \"train\" / subtype / f\"{img_path.stem}.txt\"\n",
    "                if lbl_src.exists():\n",
    "                    shutil.copy(lbl_src, fold_dir / \"labels\" / phase / lbl_src.name)\n",
    "                    label_found = True\n",
    "                    break\n",
    "            if not label_found:\n",
    "                print(f\"[!] No Labe data for: {img_path.name}\")\n",
    "\n",
    "        for phase in [\"images\", \"labels\"]:\n",
    "            src = split_dir / phase / \"test\"\n",
    "            dst = fold_dir / phase / \"test\"\n",
    "            if not dst.exists():\n",
    "                dst.symlink_to(src)\n",
    "\n",
    "        yaml_dict = {\n",
    "            \"train\": str((fold_dir / \"images/train\").resolve()),\n",
    "            \"val\": str((fold_dir / \"images/val\").resolve()),\n",
    "            \"test\": str((fold_dir / \"images/test\").resolve()),\n",
    "            \"nc\": 1,\n",
    "            \"names\": [\"lesion\"]\n",
    "        }\n",
    "        with open(fold_dir / \"data.yaml\", \"w\") as f:\n",
    "            yaml.safe_dump(yaml_dict, f)\n",
    "\n",
    "\n",
    "        csv_src = split_dir / \"labels\" / \"test\" / \"bboxes_test.csv\"\n",
    "        csv_dst = fold_dir / \"labels\" / \"test\" / \"bboxes_test.csv\"\n",
    "        if csv_src.exists():\n",
    "            shutil.copy(csv_src, csv_dst)\n",
    "        else:\n",
    "            print(f\"[Didnt found bboxes_test.csv: {csv_src}\")\n",
    "        \n",
    "        print(f\"Fold {fold} created: {fold_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d354d3b3-4747-419e-bbb5-b2aec46b1d7a",
   "metadata": {},
   "source": [
    "# Start Train and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2788797-08c1-40fd-872f-d8a739c4afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_and_eval(\n",
    "    splits=[\"SID01\", \"SID02\"],            \n",
    "    models=[\"n\", \"m\", \"l\"],                \n",
    "    batches=[16, 32],                     \n",
    "    epochs=40,\n",
    "    lr=0.01,\n",
    "    train_project=\"maize_train\",\n",
    "    eval_project=\"maize_eval\",\n",
    "    sid02_subtypes=[None, \"drone\", \"boom\", \"handheld\"],  \n",
    "    sid03_folds=None,                     \n",
    "    device=\"0\"\n",
    "):\n",
    "    for split in splits:\n",
    "        if split == \"SID01\":\n",
    "            for model in models:\n",
    "                for batch in batches:\n",
    "                    run_name = f\"yolo11{model}_{split}_e{epochs}_b{batch}\"\n",
    "                    weights = train_model(\n",
    "                        model_size=model,\n",
    "                        split=split,\n",
    "                        epochs=epochs,\n",
    "                        batch=batch,\n",
    "                        lr=lr,\n",
    "                        project=train_project,\n",
    "                        run_name = run_name\n",
    "                    )\n",
    "                    evaluate_test_raad(\n",
    "                        model_path=weights,\n",
    "                        split=split,\n",
    "                        split_root=BASE_PATH / split,\n",
    "                        project =  eval_project,\n",
    "                        run_name=run_name\n",
    "                    )\n",
    "\n",
    "        elif split == \"SID02\":\n",
    "            for subtype in sid02_subtypes:\n",
    "                subtype_tag = subtype if subtype else \"all\"\n",
    "                subset_root = _make_sid02_subset(BASE_PATH / \"SID02\", subtype) if subtype else BASE_PATH / \"SID02\"\n",
    "\n",
    "                for model in models:\n",
    "                    for batch in batches:\n",
    "                        run_name = f\"yolo11{model}_{split}_{subtype}_e{epochs}_b{batch}\"\n",
    "                        weights = train_model(\n",
    "                            model_size=model,\n",
    "                            split=\"SID02\",\n",
    "                            subtype=subtype,\n",
    "                            epochs=epochs,\n",
    "                            batch=batch,\n",
    "                            lr=lr,\n",
    "                            project=train_project,\n",
    "                            run_name=run_name\n",
    "                        )\n",
    "                        evaluate_test_raad(\n",
    "                            model_path=weights,\n",
    "                            split=\"SID02\",\n",
    "                            split_root=subset_root,\n",
    "                            project =  eval_project,\n",
    "                            run_name=run_name\n",
    "                        )\n",
    "\n",
    "        elif split == \"SID03\":\n",
    "            sid03_kfold_root = BASE_PATH / \"SID03_kfold\"\n",
    "            if not sid03_kfold_root.exists():\n",
    "                print(\"SID03_kfold not found â€“ generate K-Folds...\")\n",
    "                generate_kfold_yamls(BASE_PATH / \"SID03\", k=5)\n",
    "        \n",
    "            folds = sid03_folds if sid03_folds else [None]\n",
    "\n",
    "            for fold in folds:\n",
    "                for model in models:\n",
    "                    for batch in batches:\n",
    "                        run_name = f\"yolo11{model}_{split}_f{fold}_e{epochs}_b{batch}\"\n",
    "                        weights = train_model(\n",
    "                            model_size=model,\n",
    "                            split=\"SID03\",\n",
    "                            fold_id=fold,\n",
    "                            epochs=epochs,\n",
    "                            batch=batch,\n",
    "                            lr=lr,\n",
    "                            project=train_project,\n",
    "                            run_name=run_name\n",
    "                        )\n",
    "                        fold_path = (BASE_PATH / \"SID03_kfold\" / f\"fold{fold}\") if fold is not None else BASE_PATH / \"SID03\"\n",
    "                        sid03_test_root = BASE_PATH / \"SID03\"\n",
    "                        evaluate_test_raad(\n",
    "                            model_path=weights,\n",
    "                            split=\"SID03\",\n",
    "                            split_root=sid03_test_root,\n",
    "                            project=eval_project,\n",
    "                            run_name=run_name\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eabfa73e-039e-4526-a87c-30b924caf5f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "YAML nicht gefunden: /exchange/dspro2/M-AI-ZE/data/adjusted/1.2/splits/SID01/data.yaml",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun_training_and_eval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplits\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSID01\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ms\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_project\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTRAIN_PROJECT_PREFIX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_project\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEVAL_PROJECT_PREFIX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43msid02_subtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mboom\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdrone\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhandheld\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43msid03_folds\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mrun_training_and_eval\u001b[39m\u001b[34m(splits, models, batches, epochs, lr, train_project, eval_project, sid02_subtypes, sid03_folds, device)\u001b[39m\n\u001b[32m     16\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[32m     17\u001b[39m             run_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33myolo11\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_e\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_b\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m             weights = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmodel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m                \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m                \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m                \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m                \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m             evaluate_test_raad(\n\u001b[32m     28\u001b[39m                 model_path=weights,\n\u001b[32m     29\u001b[39m                 split=split,\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m                 run_name=run_name\n\u001b[32m     33\u001b[39m             )\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m split == \u001b[33m\"\u001b[39m\u001b[33mSID02\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model_size, split, subtype, fold_id, epochs, batch, lr, project, run_name)\u001b[39m\n\u001b[32m     21\u001b[39m dataset_yaml = split_root / \u001b[33m\"\u001b[39m\u001b[33mdata.yaml\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dataset_yaml.exists():\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYAML nicht gefunden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_yaml\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m model_file = MODEL_WEIGHTS[model_size]\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: YAML nicht gefunden: /exchange/dspro2/M-AI-ZE/data/adjusted/1.2/splits/SID01/data.yaml"
     ]
    }
   ],
   "source": [
    "run_training_and_eval(\n",
    "    splits=[\"SID01\"],\n",
    "    models=[\"s\",\"n\",\"m\",\"l\"],\n",
    "    batches=[8, 16],\n",
    "    epochs=25,\n",
    "    train_project=TRAIN_PROJECT_PREFIX,\n",
    "    eval_project=EVAL_PROJECT_PREFIX,\n",
    "    sid02_subtypes=[\"boom\", \"drone\",\"handheld\"],\n",
    "    sid03_folds=[3, 4],\n",
    "    device=\"0\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
