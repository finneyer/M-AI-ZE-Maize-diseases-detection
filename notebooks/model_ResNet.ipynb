{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d11444d-4a37-4242-a2dd-64a83c721bf8",
   "metadata": {},
   "source": [
    "# ResNet Classifier\n",
    "As a ResNet Model will be trained. It should help us better understand the performance of the different Yolo Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf2bc0b3-9922-4b22-9268-cb2b8e0d1561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in /opt/conda/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.12/site-packages (from dotenv) (1.1.0)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.12/site-packages (0.19.11)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.12/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.12/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (5.28.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (6.1.1)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.10.6)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.12/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.27.0)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.12/site-packages (from wandb) (1.3.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from wandb) (75.8.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.12/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2024.12.14)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install dotenv\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f50edd79-1c37-4218-8faf-8e39f7a75d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fefa102-b160-42c1-b14a-474ce0149f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WANDB_API_KEY: [69ca...]\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "print(f\"WANDB_API_KEY: [{wandb_api_key[:4]}...]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7945424-eadb-4480-af0c-37eb29d3c99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrueedi-tobias\u001b[0m (\u001b[33mrueedi-tobias-hochschule-luzern\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=wandb_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b092b930-6d5e-4b0d-a7b2-8bfcebcce389",
   "metadata": {},
   "source": [
    "## Sweep Training for Baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd86a23c-ee15-4a15-b5f4-87070cfc74d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/DSPRO2/M-AI-ZE-Maize-diseases-detection/notebooks/wandb/run-20250509_144317-7j1wa2oo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_resnet_test/runs/7j1wa2oo' target=\"_blank\">resnet_training</a></strong> to <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_resnet_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_resnet_test' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_resnet_test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_resnet_test/runs/7j1wa2oo' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_resnet_test/runs/7j1wa2oo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"maize_resnet_test\", name=\"resnet_training\")\n",
    "\n",
    "config = wandb.config\n",
    "config.epochs = 10\n",
    "config.batch_size = 32\n",
    "config.lr = 0.001\n",
    "config.weight_decay = 0.0001\n",
    "config.img_size = 224\n",
    "config.num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f9a364-c647-4929-9cde-9095683a90d4",
   "metadata": {},
   "source": [
    "### Get Data and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "690073a2-4300-4e9f-94a0-6d96e4f26a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMG_DIR = \"/exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/images/train\"\n",
    "VAL_IMG_DIR = \"/exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/images/val\"\n",
    "TRAIN_LABEL_DIR = \"/exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/labels/train\"\n",
    "VAL_LABEL_DIR = \"/exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/labels/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d6109c5-0245-4c4b-8608-1472788c2783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_level_labels(yolo_label_dir, image_filenames):\n",
    "    labels = {}\n",
    "    for img in image_filenames:\n",
    "        label_file = os.path.splitext(os.path.basename(img))[0] + \".txt\"\n",
    "        label_path = os.path.join(yolo_label_dir, label_file)\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "                if len(lines) > 0:\n",
    "                    labels[img] = 1\n",
    "                else:\n",
    "                    labels[img] = 0\n",
    "        else:\n",
    "            labels[img] = 0\n",
    "    return labels\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((config.img_size, config.img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a0f1e9-a61f-4a39-960d-709f4e929910",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dc14331-874e-4e8b-b5c7-9efa07161230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(image_dir, label_dir):\n",
    "    image_paths = list(Path(image_dir).glob(\"*.jpg\"))\n",
    "    labels = get_image_level_labels(label_dir, image_paths)\n",
    "\n",
    "    data = []\n",
    "    for img_path in image_paths:\n",
    "        label = labels[img_path]\n",
    "        data.append((img_path, label))\n",
    "    return data\n",
    "\n",
    "class SimpleImageDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label, str(img_path)  # Convert Path object to string\n",
    "\n",
    "\n",
    "train_data = create_dataset(TRAIN_IMG_DIR, TRAIN_LABEL_DIR)\n",
    "val_data = create_dataset(VAL_IMG_DIR, VAL_LABEL_DIR)\n",
    "\n",
    "train_dataset = SimpleImageDataset(train_data, transform=transform)\n",
    "val_dataset = SimpleImageDataset(val_data, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fbe75e-7288-4958-aed2-dd69d4c8e4ed",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dd9ddeb-04a2-4483-a180-94aee1bf719a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, config.num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e7dce8-7710-4ae8-8dad-1e452c84afab",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1ae9253-772c-4702-b79e-093f10036fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 340/340 [01:59<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train Loss: 0.0018, Train Acc: 0.9999 - Val Loss: 0.0000, Val Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 340/340 [01:59<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Train Loss: 0.0007, Train Acc: 0.9998 - Val Loss: 0.0000, Val Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 340/340 [01:59<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Train Loss: 0.0000, Train Acc: 1.0000 - Val Loss: 0.0001, Val Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 340/340 [01:59<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Train Loss: 0.0001, Train Acc: 1.0000 - Val Loss: 0.0001, Val Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 340/340 [01:59<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Train Loss: 0.0001, Train Acc: 1.0000 - Val Loss: 0.0001, Val Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 340/340 [01:59<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Train Loss: 0.0001, Train Acc: 1.0000 - Val Loss: 0.0001, Val Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 340/340 [01:59<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Train Loss: 0.0001, Train Acc: 1.0000 - Val Loss: 0.0001, Val Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 340/340 [01:59<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Train Loss: 0.0001, Train Acc: 1.0000 - Val Loss: 0.0001, Val Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 340/340 [01:59<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Train Loss: 0.0001, Train Acc: 1.0000 - Val Loss: 0.0001, Val Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 340/340 [01:59<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Train Loss: 0.0001, Train Acc: 1.0000 - Val Loss: 0.0001, Val Acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▅▁████████</td></tr><tr><td>train_loss</td><td>█▄▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▂▁▄██▇▆▄▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_accuracy</td><td>1</td></tr><tr><td>train_loss</td><td>5e-05</td></tr><tr><td>val_accuracy</td><td>1</td></tr><tr><td>val_loss</td><td>5e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet_training</strong> at: <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_resnet_test/runs/7j1wa2oo' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_resnet_test/runs/7j1wa2oo</a><br> View project at: <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_resnet_test' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_resnet_test</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250509_144317-7j1wa2oo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(config.epochs):\n",
    "    model.train()\n",
    "    train_loss, train_correct, train_total = 0, 0, 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.epochs}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_acc = train_correct / train_total\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_accuracy\": val_acc\n",
    "    })\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{config.epochs} - \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} - \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1de51d-416c-45d9-99b8-5705ebd3cd48",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d2cad8-3592-4b51-a237-eeb02fa66d7e",
   "metadata": {},
   "source": [
    "Accuracy is too good. (100%)  \n",
    "Problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a985cfee-cd08-47b3-b308-a389593d3d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of overlapping images: 0\n",
      "Overlapping images: set()\n"
     ]
    }
   ],
   "source": [
    "train_images = set()\n",
    "val_images = set()\n",
    "\n",
    "for batch in train_loader:\n",
    "    inputs, labels, paths = batch\n",
    "    train_images.update(paths)\n",
    "\n",
    "for batch in val_loader:\n",
    "    inputs, labels, paths = batch\n",
    "    val_images.update(paths)\n",
    "\n",
    "overlap = train_images.intersection(val_images)\n",
    "print(f\"Number of overlapping images: {len(overlap)}\")\n",
    "print(f\"Overlapping images: {overlap}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d7986db-1943-4f2a-a7c5-ccc50b9b2466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution in validation set:\n",
      "Label 1: 1357\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "val_labels = []\n",
    "\n",
    "for _, labels, _ in val_loader:\n",
    "    val_labels.extend(labels.tolist())\n",
    "\n",
    "label_counts = Counter(val_labels)\n",
    "print(\"Label distribution in validation set:\")\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"Label {label}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62a3270c-3474-47aa-ac81-7e4bd84dd760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Trainingsbilder: 10858\n",
      "Anzahl Validierungsbilder: 1357\n"
     ]
    }
   ],
   "source": [
    "print(f\"Trainpicture count: {len(train_images)}\")\n",
    "print(f\"Valpcture count: {len(val_images)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "417532b7-8f99-429c-8593-df0b85d10880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vorhersagen: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Tatsächliche Labels: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "inputs, labels, path = next(iter(val_loader))\n",
    "outputs = model(inputs.to(device))\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print(f\"Prediction: {predicted}\")\n",
    "print(f\"Real Labels: {labels}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf70ed6-25df-4f3e-9018-840783ce1f56",
   "metadata": {},
   "source": [
    "No label with Label 0..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daff4d95-9cce-4f0f-a889-60efac384ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
