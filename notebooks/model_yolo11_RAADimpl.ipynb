{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d11444d-4a37-4242-a2dd-64a83c721bf8",
   "metadata": {},
   "source": [
    "# Evaluate Yolov11 with RAAD\n",
    "Training Yolo11n Model and after Test with RAAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd99517-1d1a-42f8-acd9-8b7f78c2cd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /opt/conda/lib/python3.12/site-packages (8.3.142)\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.143-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.12/site-packages (0.19.11)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.1.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (1.15.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (0.21.0+cu124)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from ultralytics) (6.1.1)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.12/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.12/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.12/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (5.28.3)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.10.6)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.29.1)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.12/site-packages (from wandb) (1.3.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from wandb) (75.8.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.12/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.143-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: ultralytics\n",
      "  Attempting uninstall: ultralytics\n",
      "    Found existing installation: ultralytics 8.3.142\n",
      "    Uninstalling ultralytics-8.3.142:\n",
      "      Successfully uninstalled ultralytics-8.3.142\n",
      "Successfully installed ultralytics-8.3.143\n",
      "Requirement already satisfied: dotenv in /opt/conda/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.12/site-packages (from dotenv) (1.1.0)\n",
      "Requirement already satisfied: shapely in /opt/conda/lib/python3.12/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.12/site-packages (from shapely) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ultralytics wandb\n",
    "!pip install dotenv\n",
    "!pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab02345-a3f0-424f-9630-40700ac65d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import wandb\n",
    "from ultralytics import YOLO\n",
    "from tqdm.notebook import tqdm\n",
    "from shapely.geometry import box, MultiPolygon\n",
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a3cd17-1d51-4292-bc75-36d17d218d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONDict(\"/home/jovyan/.config/Ultralytics/settings.json\"):\n",
      "{\n",
      "  \"settings_version\": \"0.0.6\",\n",
      "  \"datasets_dir\": \"/home/jovyan/DSPRO2/M-AI-ZE-Maize-diseases-detection/notebooks/datasets\",\n",
      "  \"weights_dir\": \"weights\",\n",
      "  \"runs_dir\": \"runs\",\n",
      "  \"uuid\": \"8a115bbf5049f0fe55cf2ccd8be54ca8bfded6b963fd272724a959bb525556d2\",\n",
      "  \"sync\": true,\n",
      "  \"api_key\": \"\",\n",
      "  \"openai_api_key\": \"\",\n",
      "  \"clearml\": true,\n",
      "  \"comet\": true,\n",
      "  \"dvc\": true,\n",
      "  \"hub\": true,\n",
      "  \"mlflow\": true,\n",
      "  \"neptune\": true,\n",
      "  \"raytune\": true,\n",
      "  \"tensorboard\": false,\n",
      "  \"wandb\": true,\n",
      "  \"vscode_msg\": true,\n",
      "  \"openvino_msg\": true\n",
      "}\n",
      "💡 Learn more about Ultralytics Settings at https://docs.ultralytics.com/quickstart/#ultralytics-settings\n"
     ]
    }
   ],
   "source": [
    "# Enable W&B logging for Ultralytics\n",
    "!yolo settings wandb=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fefa102-b160-42c1-b14a-474ce0149f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WANDB_API_KEY: [69ca...]\n"
     ]
    }
   ],
   "source": [
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get and print the WANDB_API_KEY\n",
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "print(f\"WANDB_API_KEY: [{wandb_api_key[:4]}...]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7945424-eadb-4480-af0c-37eb29d3c99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrueedi-tobias\u001b[0m (\u001b[33mrueedi-tobias-hochschule-luzern\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=wandb_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c89f480-b2c4-43fa-90a5-09446cfd786e",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "953504ea-b0d4-483a-927f-1472d9511ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits\"\n",
    "splits = [\"SID01\", \"SID02\", \"SID03\"]\n",
    "test_csv_path = base_path + \"/SID01/labels/test/bboxes_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "836ac1c0-6369-41f6-8713-8d5c9177482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Split: SID01\n",
      "  Dataset Path: /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01 - Existiert: True\n",
      "  YAML Path: /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/data.yaml - Existiert: True\n",
      "  YAML Inhalt: dict_keys(['path', 'train', 'val', 'test', 'names'])\n",
      "  Train: images/train\n",
      "  Val: images/val\n",
      "  Test: images/test\n",
      "  NC: None\n",
      "  Names: {0: 'lesion'}\n",
      "\n",
      "Check Split: SID02\n",
      "  Dataset Path: /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID02 - Existiert: True\n",
      "  YAML Path: /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID02/data.yaml - Existiert: False\n",
      "\n",
      "Check Split: SID03\n",
      "  Dataset Path: /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID03 - Existiert: True\n",
      "  YAML Path: /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID03/data.yaml - Existiert: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for split in splits:\n",
    "    dataset_path = os.path.join(base_path, split)\n",
    "    yaml_path = os.path.join(dataset_path, \"data.yaml\")\n",
    "    \n",
    "    print(f\"Check Split: {split}\")\n",
    "    print(f\"  Dataset Path: {dataset_path} - Existiert: {os.path.exists(dataset_path)}\")\n",
    "    print(f\"  YAML Path: {yaml_path} - Existiert: {os.path.exists(yaml_path)}\")\n",
    "\n",
    "    if os.path.exists(yaml_path):\n",
    "        with open(yaml_path, 'r') as f:\n",
    "            data_yaml = yaml.safe_load(f)\n",
    "            print(f\"  YAML Inhalt: {data_yaml.keys()}\")\n",
    "            print(f\"  Train: {data_yaml.get('train')}\")\n",
    "            print(f\"  Val: {data_yaml.get('val')}\")\n",
    "            print(f\"  Test: {data_yaml.get('test')}\")\n",
    "            print(f\"  NC: {data_yaml.get('nc')}\")\n",
    "            print(f\"  Names: {data_yaml.get('names')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b092b930-6d5e-4b0d-a7b2-8bfcebcce389",
   "metadata": {},
   "source": [
    "## RAAD implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d7ffe35-debd-4ccd-a435-b99c01d00bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_raad(pred_boxes, true_boxes, img_width=640, img_height=640, epsilon=1e-6, normalize=True):\n",
    "    \"\"\"\n",
    "    Calculate RAAD (Relative Affected Area Difference) metric\n",
    "    \n",
    "    Args:\n",
    "        pred_boxes: List of predicted boxes in format [x1, y1, x2, y2]\n",
    "        true_boxes: List of ground truth boxes in format [x1, y1, x2, y2]\n",
    "        img_width: Width of the image\n",
    "        img_height: Height of the image\n",
    "        epsilon: Small value to avoid division by zero\n",
    "        normalize: Whether to normalize coordinates from 0-1 to image dimensions\n",
    "        \n",
    "    Returns:\n",
    "        RAAD value (lower is better), Area of predictions, Area of ground truth\n",
    "    \"\"\"\n",
    "    if len(pred_boxes) == 0 and len(true_boxes) == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    if len(pred_boxes) == 0:\n",
    "        return 1.0, 0.0, sum([(box[2]-box[0])*(box[3]-box[1]) for box in true_boxes])\n",
    "    if len(true_boxes) == 0:\n",
    "        return 1.0, sum([(box[2]-box[0])*(box[3]-box[1]) for box in pred_boxes]), 0.0\n",
    "    \n",
    "    if normalize:\n",
    "        pred_boxes = [[box[0]*img_width, box[1]*img_height, \n",
    "                      box[2]*img_width, box[3]*img_height] for box in pred_boxes]\n",
    "        true_boxes = [[box[0]*img_width, box[1]*img_height, \n",
    "                      box[2]*img_width, box[3]*img_height] for box in true_boxes]\n",
    "    \n",
    "    pred_polygons = [box(b[0], b[1], b[2], b[3]) for b in pred_boxes]\n",
    "    true_polygons = [box(b[0], b[1], b[2], b[3]) for b in true_boxes]\n",
    "    \n",
    "    if pred_polygons:\n",
    "        pred_multipolygon = MultiPolygon(pred_polygons).buffer(0)\n",
    "    else:\n",
    "        pred_multipolygon = MultiPolygon([])\n",
    "        \n",
    "    if true_polygons:\n",
    "        true_multipolygon = MultiPolygon(true_polygons).buffer(0)\n",
    "    else:\n",
    "        true_multipolygon = MultiPolygon([])\n",
    "    \n",
    "    pred_area = pred_multipolygon.area\n",
    "    true_area = true_multipolygon.area\n",
    "    \n",
    "    area_diff = abs(pred_area - true_area)\n",
    "    raad = area_diff / max(true_area, epsilon)\n",
    "    \n",
    "    return raad, pred_area, true_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "411f97d2-4d98-4eb4-88f0-2393315a7f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raad_calculation():\n",
    "    pred_boxes1 = [[100, 100, 200, 200]]\n",
    "    true_boxes1 = [[100, 100, 200, 200]]\n",
    "    \n",
    "    pred_boxes2 = [[100, 100, 200, 200]]\n",
    "    true_boxes2 = [[300, 300, 400, 400]]\n",
    "    \n",
    "    pred_boxes3 = [[100, 100, 300, 300]]\n",
    "    true_boxes3 = [[200, 200, 400, 400]]\n",
    "\n",
    "    pred_boxes4 = [[100, 100, 400, 400]]\n",
    "    true_boxes4 = [[150, 150, 300, 300]]\n",
    "    \n",
    "    pred_boxes5 = [[100, 100, 300, 300], [250, 250, 450, 450]]\n",
    "    true_boxes5 = [[150, 150, 350, 350]]\n",
    "    \n",
    "    examples = [\n",
    "        (pred_boxes1, true_boxes1, \"Identical Boxes\"),\n",
    "        (pred_boxes2, true_boxes2, \"No Overlaps\"),\n",
    "        (pred_boxes3, true_boxes3, \"Partly Overlapping\"),\n",
    "        (pred_boxes4, true_boxes4, \"Different Boxes\"),\n",
    "        (pred_boxes5, true_boxes5, \"Multiple Boxes with Overlapps\")\n",
    "    ]\n",
    "    \n",
    "    for pred_boxes, true_boxes, desc in examples:\n",
    "        raad, pred_area, true_area = calculate_raad(pred_boxes, true_boxes, normalize=False)\n",
    "        print(f\"{desc}:\")\n",
    "        print(f\"  RAAD: {raad:.4f}\")\n",
    "        print(f\"  Pred Area: {pred_area:.1f}, True Area: {true_area:.1f}\")\n",
    "        print(f\"  Area Diff: {abs(pred_area - true_area):.1f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1751c86f-bb2f-456d-af4f-e519c0a7e365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identical Boxes:\n",
      "  RAAD: 0.0000\n",
      "  Pred Area: 10000.0, True Area: 10000.0\n",
      "  Area Diff: 0.0\n",
      "\n",
      "No Overlaps:\n",
      "  RAAD: 0.0000\n",
      "  Pred Area: 10000.0, True Area: 10000.0\n",
      "  Area Diff: 0.0\n",
      "\n",
      "Partly Overlapping:\n",
      "  RAAD: 0.0000\n",
      "  Pred Area: 40000.0, True Area: 40000.0\n",
      "  Area Diff: 0.0\n",
      "\n",
      "Different Boxes:\n",
      "  RAAD: 3.0000\n",
      "  Pred Area: 90000.0, True Area: 22500.0\n",
      "  Area Diff: 67500.0\n",
      "\n",
      "Multiple Boxes with Overlapps:\n",
      "  RAAD: 0.9375\n",
      "  Pred Area: 77500.0, True Area: 40000.0\n",
      "  Area Diff: 37500.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_raad_calculation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2838ed3-e8af-4f4d-a8ec-2815249d4fba",
   "metadata": {},
   "source": [
    "## Training SID01 with RAAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "045aa155-9561-40b0-9ace-ae7b75484bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_type=\"yolo11n.pt\", split=\"SID01\", epochs=10, batch=16, lr=0.01):\n",
    "    \"\"\"\n",
    "    Train a YOLO model with RAAD metric tracking\n",
    "    \n",
    "    This version properly checks for the model file after training and handles paths correctly.\n",
    "    \"\"\"\n",
    "    dataset_yaml = f\"{base_path}/{split}/data.yaml\"\n",
    "    \n",
    "    model_name = model_type.split('.')[0]\n",
    "    \n",
    "    run_name = f\"{model_name}_{split}_raad_e{epochs}\"\n",
    "    \n",
    "    try:\n",
    "        model = YOLO(model_type)\n",
    "        \n",
    "        results = model.train(\n",
    "            data=dataset_yaml,\n",
    "            epochs=epochs,\n",
    "            imgsz=640,\n",
    "            lr0=lr,\n",
    "            batch=batch,\n",
    "            name=run_name,\n",
    "            project=\"maize_detection\",\n",
    "            exist_ok=True\n",
    "        )\n",
    "        \n",
    "        potential_paths = [\n",
    "            f\"runs/detect/{run_name}/weights/best.pt\",\n",
    "            f\"maize_detection/{run_name}/weights/best.pt\",\n",
    "            f\"runs/train/{run_name}/weights/best.pt\",\n",
    "            f\"maize_detection/{run_name}/weights/last.pt\",\n",
    "            f\"runs/detect/{run_name}/weights/last.pt\"\n",
    "        ]\n",
    "        \n",
    "        weights_path = None\n",
    "        for path in potential_paths:\n",
    "            if os.path.exists(path):\n",
    "                weights_path = path\n",
    "                print(f\"Found model weights at: {weights_path}\")\n",
    "                break\n",
    "        \n",
    "        if weights_path is None:\n",
    "            print(\"Warning: Could not find model weights file. Here are the directories in runs/:\")\n",
    "            if os.path.exists(\"runs\"):\n",
    "                print(os.listdir(\"runs\"))\n",
    "                if os.path.exists(\"runs/detect\"):\n",
    "                    print(\"Contents of runs/detect/:\")\n",
    "                    print(os.listdir(\"runs/detect\"))\n",
    "                    detect_dirs = os.listdir(\"runs/detect\")\n",
    "                    if detect_dirs:\n",
    "                        first_dir = os.path.join(\"runs/detect\", detect_dirs[0])\n",
    "                        print(f\"Contents of {first_dir}:\")\n",
    "                        print(os.listdir(first_dir))\n",
    "                        if os.path.exists(os.path.join(first_dir, \"weights\")):\n",
    "                            print(f\"Contents of {first_dir}/weights:\")\n",
    "                            print(os.listdir(os.path.join(first_dir, \"weights\")))\n",
    "            \n",
    "            print(\"Using original model as fallback since trained weights not found\")\n",
    "            return model_type  # Return the original model path\n",
    "        \n",
    "        if wandb.run is not None:\n",
    "            wandb.finish()\n",
    "        \n",
    "        wandb_config = {\n",
    "            \"model\": model_type,\n",
    "            \"epochs\": epochs,\n",
    "            \"batch\": batch,\n",
    "            \"lr\": lr,\n",
    "            \"split\": split,\n",
    "            \"weights_path\": weights_path\n",
    "        }\n",
    "        \n",
    "        additional_run = wandb.init(\n",
    "            project=f\"maize_detection_{split}_additional\", \n",
    "            name=f\"{model_name}_{split}_additional_metrics_e{epochs}\",\n",
    "            config=wandb_config,\n",
    "            reinit=True\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            metrics_table = wandb.Table(columns=[\"model\", \"split\", \"mAP50\", \"mAP50-95\", \"weights_path\"])\n",
    "            \n",
    "            map50 = results.results_dict.get('metrics/mAP50', 0)\n",
    "            map50_95 = results.results_dict.get('metrics/mAP50-95', 0)\n",
    "            \n",
    "            metrics_table.add_data(model_type, split, map50, map50_95, weights_path)\n",
    "            \n",
    "            log_dict = {\"metrics_comparison\": metrics_table}\n",
    "            \n",
    "            try:\n",
    "                val_path = os.path.join(base_path, split, \"images\", \"val\")\n",
    "                if os.path.exists(val_path):\n",
    "                    val_images = [f for f in os.listdir(val_path) if f.endswith(('.jpg', '.png'))][:5]  # Nimm die ersten 5 Bilder\n",
    "                    \n",
    "                    for i, img_file in enumerate(val_images):\n",
    "                        img_path = os.path.join(val_path, img_file)\n",
    "                        prediction_results = model.predict(img_path, conf=0.25)\n",
    "                        \n",
    "                        img = cv2.imread(img_path)\n",
    "                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                        \n",
    "                        for r in prediction_results:\n",
    "                            boxes = r.boxes\n",
    "                            for box in boxes:\n",
    "                                x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "                                conf = box.conf[0].item()\n",
    "                                \n",
    "                                cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "                                cv2.putText(img, f\"{conf:.2f}\", (int(x1), int(y1) - 10), \n",
    "                                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                        \n",
    "                        log_dict[f\"validation_image_{i}\"] = wandb.Image(img, caption=img_file)\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"Fehler beim Visualisieren der Validierungsbilder: {e}\")\n",
    "                \n",
    "            # Make a single log call with all our data\n",
    "            additional_run.log(log_dict)\n",
    "            \n",
    "        finally:\n",
    "            additional_run.finish()\n",
    "        \n",
    "        return weights_path\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during training: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return model_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b1ea1a-45b3-4a04-8552-b2cb4a2944f0",
   "metadata": {},
   "source": [
    "## Evaluate RAAD on Testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bb00c11-90da-4bed-9718-10809b9c74d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suppress_yolo_logging():\n",
    "    \"\"\"Suppress the YOLO logging temporarily.\"\"\"\n",
    "    logger = logging.getLogger(\"ultralytics\")\n",
    "    original_level = logger.level\n",
    "    logger.setLevel(logging.ERROR)  # Zeige nur Fehler an\n",
    "    return logger, original_level\n",
    "\n",
    "def restore_yolo_logging(logger, original_level):\n",
    "    \"\"\"Restore the YOLO logging to its original level.\"\"\"\n",
    "    logger.setLevel(original_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8d10545-e736-4cb6-b529-94dbaeeccc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bounding_boxes_from_csv(csv_path):\n",
    "    \"\"\"\n",
    "    Load bounding boxes from a single CSV file.\n",
    "    \n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary where keys are image names and values are lists of bounding boxes.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, header=None, skiprows=1)\n",
    "    bounding_boxes = {}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        img_name = row[0]\n",
    "        x1, y1, x2, y2 = map(int, [row[1], row[2], row[3], row[4]])\n",
    "\n",
    "        if img_name not in bounding_boxes:\n",
    "            bounding_boxes[img_name] = []\n",
    "        bounding_boxes[img_name].append((x1, y1, x2, y2))\n",
    "\n",
    "    print(f\"Loaded bounding boxes for {len(bounding_boxes)} images.\")\n",
    "    return bounding_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2080b9f0-1991-41f5-9824-35436c7273c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test_raad(model_path, bounding_boxes, split=\"SID01\"):\n",
    "    \"\"\"\n",
    "    Evaluate a trained model on test data with RAAD metric.\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Path to the YOLO model file.\n",
    "        bounding_boxes (dict): Dictionary with image names as keys and box lists as values.\n",
    "        split (str): Data split name.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Evaluation results with RAAD values.\n",
    "    \"\"\"\n",
    "    model_name = os.path.basename(model_path).split('.')[0]\n",
    "    \n",
    "    run = wandb.init(project=\"maize_detection_test\", \n",
    "                    name=f\"test_evaluation_{model_name}_{split}\",\n",
    "                    config={\"model_path\": model_path, \"split\": split})\n",
    "    \n",
    "    try:\n",
    "        test_images_dir = f\"{base_path}/{split}/images/test\"\n",
    "        \n",
    "        model = YOLO(model_path)\n",
    "        \n",
    "        results = {\n",
    "            'image': [],\n",
    "            'raad': [],\n",
    "            'pred_area': [],\n",
    "            'true_area': [],\n",
    "            'prediction_count': [],\n",
    "            'truth_count': []\n",
    "        }\n",
    "        \n",
    "        test_images = [f for f in os.listdir(test_images_dir) if f.endswith(('.jpg', '.png'))]\n",
    "        \n",
    "        for img_file in tqdm(test_images, desc=\"Evaluating test images\"):\n",
    "            img_path = os.path.join(test_images_dir, img_file)\n",
    "            \n",
    "            if img_file not in bounding_boxes:\n",
    "                print(f\"No ground truth for image: {img_file}\")\n",
    "                continue\n",
    "            \n",
    "            img = cv2.imread(img_path)\n",
    "            img_height, img_width = img.shape[:2]\n",
    "            \n",
    "            logger, original_level = suppress_yolo_logging()\n",
    "            try:\n",
    "                predictions = model.predict(img_path, save=False)\n",
    "            finally:\n",
    "                restore_yolo_logging(logger, original_level)\n",
    "\n",
    "            \n",
    "            pred_boxes = [\n",
    "                [int(box[0]), int(box[1]), int(box[2]), int(box[3])]\n",
    "                for r in predictions for box in r.boxes.xyxy.cpu().numpy()\n",
    "            ]\n",
    "\n",
    "            logger, original_level = suppress_yolo_logging()\n",
    "            \n",
    "            true_boxes = bounding_boxes[img_file]\n",
    "            \n",
    "            raad, pred_area, true_area = calculate_raad(pred_boxes, true_boxes, img_width, img_height, normalize=False)\n",
    "            \n",
    "            results['image'].append(img_file)\n",
    "            results['raad'].append(raad)\n",
    "            results['pred_area'].append(pred_area)\n",
    "            results['true_area'].append(true_area)\n",
    "            results['prediction_count'].append(len(pred_boxes))\n",
    "            results['truth_count'].append(len(true_boxes))\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        avg_raad = results_df['raad'].mean()\n",
    "        print(f\"Average RAAD on test set: {avg_raad:.4f}\")\n",
    "        run.log({\"test/avg_raad\": avg_raad})\n",
    "        run.finish()\n",
    "        \n",
    "        return results_df, avg_raad\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during RAAD evaluation: {e}\")\n",
    "        run.finish()\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3f29467-f553-4915-abe6-bfdcb348a92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.139 🚀 Python-3.12.8 torch-2.6.0+cu124 CUDA:0 (NVIDIA A16, 14891MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11n_SID01_raad_e1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=maize_detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=maize_detection/yolo11n_SID01_raad_e1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/DSPRO2/M-AI-ZE-Maize-diseases-detection/notebooks/wandb/run-20250518_202411-ybhr4jvd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection/runs/ybhr4jvd' target=\"_blank\">yolo11n_SID01_raad_e1</a></strong> to <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection/runs/ybhr4jvd' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection/runs/ybhr4jvd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1622.2±697.2 MB/s, size: 59.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/labels/train.cache... 10858 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10858/10858 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1735.3±896.9 MB/s, size: 56.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/labels/val.cache... 1357 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1357/1357 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to maize_detection/yolo11n_SID01_raad_e1/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mmaize_detection/yolo11n_SID01_raad_e1\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      2.84G      2.273      2.367      1.568        104        640: 100%|██████████| 679/679 [02:53<00:00,  3.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 43/43 [00:13<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.462      0.378      0.367      0.148\n",
      "\n",
      "1 epochs completed in 0.053 hours.\n",
      "Optimizer stripped from maize_detection/yolo11n_SID01_raad_e1/weights/last.pt, 5.5MB\n",
      "Optimizer stripped from maize_detection/yolo11n_SID01_raad_e1/weights/best.pt, 5.5MB\n",
      "\n",
      "Validating maize_detection/yolo11n_SID01_raad_e1/weights/best.pt...\n",
      "Ultralytics 8.3.139 🚀 Python-3.12.8 torch-2.6.0+cu124 CUDA:0 (NVIDIA A16, 14891MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 43/43 [00:10<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1357      10668      0.463      0.379      0.367      0.148\n",
      "Speed: 0.3ms preprocess, 3.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mmaize_detection/yolo11n_SID01_raad_e1\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>▁</td></tr><tr><td>lr/pg1</td><td>▁</td></tr><tr><td>lr/pg2</td><td>▁</td></tr><tr><td>metrics/mAP50(B)</td><td>▁</td></tr><tr><td>metrics/mAP50-95(B)</td><td>▁</td></tr><tr><td>metrics/precision(B)</td><td>▁</td></tr><tr><td>metrics/recall(B)</td><td>▁</td></tr><tr><td>model/GFLOPs</td><td>▁</td></tr><tr><td>model/parameters</td><td>▁</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>▁</td></tr><tr><td>train/box_loss</td><td>▁</td></tr><tr><td>train/cls_loss</td><td>▁</td></tr><tr><td>train/dfl_loss</td><td>▁</td></tr><tr><td>val/box_loss</td><td>▁</td></tr><tr><td>val/cls_loss</td><td>▁</td></tr><tr><td>val/dfl_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.00067</td></tr><tr><td>lr/pg1</td><td>0.00067</td></tr><tr><td>lr/pg2</td><td>0.00067</td></tr><tr><td>metrics/mAP50(B)</td><td>0.36738</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.14825</td></tr><tr><td>metrics/precision(B)</td><td>0.46293</td></tr><tr><td>metrics/recall(B)</td><td>0.37861</td></tr><tr><td>model/GFLOPs</td><td>6.441</td></tr><tr><td>model/parameters</td><td>2590035</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>3.794</td></tr><tr><td>train/box_loss</td><td>2.27294</td></tr><tr><td>train/cls_loss</td><td>2.36705</td></tr><tr><td>train/dfl_loss</td><td>1.56825</td></tr><tr><td>val/box_loss</td><td>2.04163</td></tr><tr><td>val/cls_loss</td><td>1.79392</td></tr><tr><td>val/dfl_loss</td><td>1.48497</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n_SID01_raad_e1</strong> at: <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection/runs/ybhr4jvd' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection/runs/ybhr4jvd</a><br> View project at: <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection</a><br>Synced 5 W&B file(s), 28 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250518_202411-ybhr4jvd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model weights at: maize_detection/yolo11n_SID01_raad_e1/weights/best.pt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/DSPRO2/M-AI-ZE-Maize-diseases-detection/notebooks/wandb/run-20250518_202749-5axcx2g6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_SID01_additional/runs/5axcx2g6' target=\"_blank\">yolo11n_SID01_additional_metrics_e1</a></strong> to <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_SID01_additional' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_SID01_additional' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_SID01_additional</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_SID01_additional/runs/5axcx2g6' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_SID01_additional/runs/5axcx2g6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/images/val/DSC02226_2.jpg: 640x640 4 lesions, 6.6ms\n",
      "Speed: 1.4ms preprocess, 6.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/images/val/J_170911_134911.jpg: 640x640 2 lesions, 7.2ms\n",
      "Speed: 1.3ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/images/val/J_170825_145123.jpg: 640x640 (no detections), 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/images/val/DSC03294_0.jpg: 640x640 4 lesions, 7.2ms\n",
      "Speed: 1.3ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/images/val/J_170830_154632.jpg: 640x640 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n_SID01_additional_metrics_e1</strong> at: <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_SID01_additional/runs/5axcx2g6' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_SID01_additional/runs/5axcx2g6</a><br> View project at: <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_SID01_additional' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_SID01_additional</a><br>Synced 5 W&B file(s), 6 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250518_202749-5axcx2g6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Modell saved at: maize_detection/yolo11n_SID01_raad_e1/weights/best.pt\n"
     ]
    }
   ],
   "source": [
    "weights_path = train_model(model_type=\"yolo11n.pt\", split=\"SID01\", epochs=1, batch=16, lr=0.01)\n",
    "print(f\"Trained Modell saved at: {weights_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87e6b8b1-1f0a-4a63-98bd-726cbe8c467c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded bounding boxes for 1358 images.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/DSPRO2/M-AI-ZE-Maize-diseases-detection/notebooks/wandb/run-20250518_202754-m5j8dxv9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test/runs/m5j8dxv9' target=\"_blank\">test_evaluation_best_SID01</a></strong> to <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test/runs/m5j8dxv9' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test/runs/m5j8dxv9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f9da2be7c440c6bc9541a5aae9d73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating test images:   0%|          | 0/1358 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RAAD on test set: 0.9170\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test/avg_raad</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test/avg_raad</td><td>0.917</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test_evaluation_best_SID01</strong> at: <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test/runs/m5j8dxv9' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test/runs/m5j8dxv9</a><br> View project at: <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_test</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250518_202754-m5j8dxv9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bounding_boxes = load_bounding_boxes_from_csv(test_csv_path)\n",
    "test_results, avg_raad = evaluate_test_raad(weights_path, bounding_boxes, split=\"SID01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d16f6e-a7cb-494b-a631-65326f061309",
   "metadata": {},
   "source": [
    "## Multiple Models:\n",
    "Work in Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e8947c-9d77-41fc-b07e-ee332a88cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multiple_models(model_types, splits, epochs_list, batch=16, lr=0.01):\n",
    "    \"\"\"\n",
    "    Train multiple YOLO models with various configurations\n",
    "    \n",
    "    Args:\n",
    "        model_types: List of model types (e.g. [\"yolo11n.pt\", \"yolo11l.pt\"])\n",
    "        splits: List of splits to train on (e.g. [\"SID01\", \"SID02\"])\n",
    "        epochs_list: List of epoch numbers to train for each model\n",
    "        batch: Batch size\n",
    "        lr: Learning rate\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with training results\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for model_type in model_types:\n",
    "        for split in splits:\n",
    "            for epochs in epochs_list:\n",
    "                print(f\"\\n=== Training {model_type} on {split} for {epochs} epochs ===\")\n",
    "                \n",
    "                config_key = f\"{model_type.split('.')[0]}_{split}_e{epochs}\"\n",
    "                \n",
    "                try:\n",
    "                    weights_path = train_model(model_type=model_type, split=split, epochs=epochs, batch=batch, lr=lr)\n",
    "                    \n",
    "                    print(f\"\\n=== Evaluating {model_type} on {split} test set ===\")\n",
    "                    _, avg_raad = evaluate_test_raad(weights_path, split=split)\n",
    "                    \n",
    "                    results[config_key] = {\n",
    "                        \"model_type\": model_type,\n",
    "                        \"split\": split,\n",
    "                        \"epochs\": epochs,\n",
    "                        \"weights_path\": weights_path,\n",
    "                        \"avg_raad\": avg_raad\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"Completed training and evaluation for {config_key}\")\n",
    "                    print(f\"Model saved at: {weights_path}\")\n",
    "                    print(f\"Average RAAD: {avg_raad:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error training {config_key}: {e}\")\n",
    "                    results[config_key] = {\n",
    "                        \"model_type\": model_type,\n",
    "                        \"split\": split,\n",
    "                        \"epochs\": epochs,\n",
    "                        \"error\": str(e)\n",
    "                    }\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5042334-ff66-4838-a663-48c8b56e2800",
   "metadata": {},
   "source": [
    "## Training SID01 with Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6bf51cc7-f735-4ca3-aa4e-da50ade01e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training multiple YOLO models ===\n",
      "\n",
      "=== Training yolo11n.pt on SID01 for 10 epochs ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/DSPRO2/M-AI-ZE-Maize-diseases-detection/notebooks/wandb/run-20250518_135237-p3saecvs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_SID01/runs/p3saecvs' target=\"_blank\">yolo11n_SID01_raad_e10</a></strong> to <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_SID01' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_SID01' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_SID01</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_SID01/runs/p3saecvs' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_SID01/runs/p3saecvs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.139 🚀 Python-3.12.8 torch-2.6.0+cu124 CUDA:0 (NVIDIA A16, 14891MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11n_SID01_raad_e10, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=maize_detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=maize_detection/yolo11n_SID01_raad_e10, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2491.4±832.8 MB/s, size: 59.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/labels/train.cache... 10858 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10858/10858 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1270.9±807.5 MB/s, size: 56.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits/SID01/labels/val.cache... 1357 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1357/1357 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to maize_detection/yolo11n_SID01_raad_e10/labels.jpg... \n",
      "WARNING ⚠️ \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mmaize_detection/yolo11n_SID01_raad_e10\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-38 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/opt/conda/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 59, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 35, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^Exception in thread ^Thread-39 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "^    self.run()\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/opt/conda/lib/python3.12/threading.py\", line 1012, in run\n",
      "    ^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n",
      "self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 59, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 35, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "        ^^^^^^^^^^^^^^    ^^^^^^^^fd = df.detach()^\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^  File \"/opt/conda/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "^^^^^    ^return _ForkingPickler.loads(res)^\n",
      "^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^\n",
      "^^  File \"/opt/conda/lib/python3.12/multiprocessing/connection.py\", line 519, in Client\n",
      "^^^    ^c = SocketClient(address)^\n",
      "^^ ^ ^ ^ ^ ^ ^ ^ ^^\n",
      "^^  File \"/opt/conda/lib/python3.12/site-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n",
      "^^^^    ^fd = df.detach()^\n",
      "^^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^\n",
      "^^  File \"/opt/conda/lib/python3.12/multiprocessing/connection.py\", line 647, in SocketClient\n",
      "^^    ^s.connect(address)^\n",
      "^: ileNotFoundError\n",
      "[Errno 2] No such file or directory\n",
      "  File \"/opt/conda/lib/python3.12/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  File \"/opt/conda/lib/python3.12/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/multiprocessing/connection.py\", line 519, in Client\n",
      "    c = SocketClient(address)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/multiprocessing/connection.py\", line 647, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "      with _resource_sharer.get_connection(self._id) as conn:  110        640:   1%|          | 7/679 [00:02<02:56,  3.81it/s]\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/opt/conda/lib/python3.12/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "^^^Exception in thread Thread-40 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/opt/conda/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 59, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 35, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/multiprocessing/connection.py\", line 519, in Client\n",
      "    c = SocketClient(address)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/multiprocessing/connection.py\", line 647, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "       1/10       2.4G      3.088      4.264      2.409        110        640:   1%|          | 7/679 [00:02<03:45,  2.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n_SID01_raad_e10</strong> at: <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_SID01/runs/p3saecvs' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_SID01/runs/p3saecvs</a><br> View project at: <a href='https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_SID01' target=\"_blank\">https://wandb.ai/rueedi-tobias-hochschule-luzern/maize_detection_SID01</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250518_135237-p3saecvs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Wenn das Skript direkt ausgeführt wird\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 12\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Starte das Training aller Modelle\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Training multiple YOLO models ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_multiple_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Zeige die Zusammenfassung der Ergebnisse\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Training Results Summary ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[46], line 27\u001b[0m, in \u001b[0;36mtrain_multiple_models\u001b[0;34m(model_types, splits, epochs_list, batch, lr)\u001b[0m\n\u001b[1;32m     23\u001b[0m config_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_e\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     weights_path \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# Evaluate on test data\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Evaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m test set ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[44], line 33\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model_type, split, epochs, batch, lr)\u001b[0m\n\u001b[1;32m     30\u001b[0m run_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_raad_e\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_yaml\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaize_detection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     42\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Speicherpfad des Modells\u001b[39;00m\n\u001b[1;32m     45\u001b[0m weights_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns/detect/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/weights/best.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/ultralytics/engine/model.py:793\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/ultralytics/engine/trainer.py:211\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/ultralytics/engine/trainer.py:403\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ni \u001b[38;5;241m-\u001b[39m last_opt_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulate:\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     last_opt_step \u001b[38;5;241m=\u001b[39m ni\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# Timed stopping\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/ultralytics/engine/trainer.py:622\u001b[0m, in \u001b[0;36mBaseTrainer.optimizer_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39munscale_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer)  \u001b[38;5;66;03m# unscale gradients\u001b[39;00m\n\u001b[1;32m    621\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10.0\u001b[39m)  \u001b[38;5;66;03m# clip gradients\u001b[39;00m\n\u001b[0;32m--> 622\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/amp/grad_scaler.py:457\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    455\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 457\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    wandb.login()\n",
    "    \n",
    "    model_types = [\"yolo11n.pt\", \"yolo11l.pt\", \"yolo11m.pt\"]\n",
    "    splits = [\"SID01\"]\n",
    "    #splits = [\"SID01\", \"SID02\", \"SID03\"]\n",
    "    epochs_list = [40]\n",
    "    batch = [16, 32]\n",
    "    \n",
    "    print(\"=== Training multiple YOLO models ===\")\n",
    "    results = train_multiple_models(\n",
    "        model_types=model_types,\n",
    "        splits=splits,\n",
    "        epochs_list=epochs_list,\n",
    "        batch=16,\n",
    "        lr=0.01\n",
    "    )\n",
    "    \n",
    "    print(\"\\n=== Training Results Summary ===\")\n",
    "    for config_key, result in results.items():\n",
    "        if \"error\" in result:\n",
    "            print(f\"{config_key}: Failed - {result['error']}\")\n",
    "        else:\n",
    "            print(f\"{config_key}: RAAD = {result['avg_raad']:.4f}, Model: {result['weights_path']}\")\n",
    "    \n",
    "    print(\"\\n=== Training Complete ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c4c424-ac42-4a10-a1a4-41caf1467c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all_splits(model_type=\"yolo11n.pt\", epochs=10):\n",
    "    \"\"\"\n",
    "    Train on all splits and compare results\n",
    "    \"\"\"\n",
    "    splits = [\"SID01\", \"SID02\", \"SID03\"]\n",
    "    base_path = \"/exchange/dspro2/M-AI-ZE/data/adjusted/1.1/splits\"\n",
    "    \n",
    "    # Summary metrics\n",
    "    summary_table = wandb.Table(columns=[\"model\", \"split\", \"mAP50\", \"RAAD\", \"training_time\"])\n",
    "    \n",
    "    for split in splits:\n",
    "        # SID03 uses k-fold\n",
    "        if split == \"SID03\":\n",
    "            # Implement simple 2-fold cross-validation\n",
    "            # For SID03 which doesn't have validation set\n",
    "            train_folders = [\n",
    "                f\"{base_path}/{split}/labels/train/boom\",\n",
    "                f\"{base_path}/{split}/labels/train/drone\",\n",
    "                f\"{base_path}/{split}/labels/train/handheld\"\n",
    "            ]\n",
    "            \n",
    "            # Get all training files from all folders\n",
    "            all_files = []\n",
    "            for folder in train_folders:\n",
    "                files = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.txt')]\n",
    "                all_files.extend(files)\n",
    "            \n",
    "            # Split into two folds\n",
    "            import random\n",
    "            random.shuffle(all_files)\n",
    "            fold_size = len(all_files) // 2\n",
    "            fold1 = all_files[:fold_size]\n",
    "            fold2 = all_files[fold_size:]\n",
    "            \n",
    "            # Create temporary data yamls for each fold\n",
    "            fold1_yaml = f\"{base_path}/{split}/data_fold1.yaml\"\n",
    "            fold2_yaml = f\"{base_path}/{split}/data_fold2.yaml\"\n",
    "            \n",
    "            # Create yamls (simplified, you'll need to adapt this)\n",
    "            with open(f\"{base_path}/{split}/data.yaml\", 'r') as f:\n",
    "                data_yaml = f.read()\n",
    "            \n",
    "            # Save fold yaml files\n",
    "            # This is simplified - you'll need to adapt this to create proper yamls\n",
    "            \n",
    "            # Train on fold 1, validate on fold 2\n",
    "            run = wandb.init(project=f\"maize_detection_splits\", \n",
    "                            name=f\"{model_type.split('.')[0]}_{split}_fold1\",\n",
    "                            config={\n",
    "                                \"model\": model_type,\n",
    "                                \"epochs\": epochs,\n",
    "                                \"split\": f\"{split}_fold1\"\n",
    "                            })\n",
    "            \n",
    "            model = YOLO(model_type)\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Train (simplified)\n",
    "            results = model.train(\n",
    "                data=fold1_yaml,  # You'll need to create this\n",
    "                epochs=epochs,\n",
    "                imgsz=640,\n",
    "                name=f\"{model_type.split('.')[0]}_{split}_fold1\",\n",
    "                project=\"maize_detection_splits\",\n",
    "                exist_ok=True\n",
    "            )\n",
    "            \n",
    "            training_time = time.time() - start_time\n",
    "            \n",
    "            # Add to summary\n",
    "            map50 = results.results_dict.get('metrics/mAP50', 0)\n",
    "            raad_value = results.results_dict.get('raad', 0)\n",
    "            \n",
    "            summary_table.add_data(model_type, f\"{split}_fold1\", map50, raad_value, training_time)\n",
    "            \n",
    "            run.finish()\n",
    "            \n",
    "            # Repeat for fold 2 (code omitted for brevity)\n",
    "            \n",
    "        else:\n",
    "            # Regular training for SID01 and SID02\n",
    "            dataset_yaml = f\"{base_path}/{split}/data.yaml\"\n",
    "            \n",
    "            run = wandb.init(project=f\"maize_detection_splits\", \n",
    "                            name=f\"{model_type.split('.')[0]}_{split}\",\n",
    "                            config={\n",
    "                                \"model\": model_type,\n",
    "                                \"epochs\": epochs,\n",
    "                                \"split\": split\n",
    "                            })\n",
    "            \n",
    "            model = YOLO(model_type)\n",
    "            start_time = time.time()\n",
    "            \n",
    "            results = model.train(\n",
    "                data=dataset_yaml,\n",
    "                epochs=epochs,\n",
    "                imgsz=640,\n",
    "                name=f\"{model_type.split('.')[0]}_{split}\",\n",
    "                project=\"maize_detection_splits\",\n",
    "                exist_ok=True\n",
    "            )\n",
    "            \n",
    "            training_time = time.time() - start_time\n",
    "            \n",
    "            # Add to summary\n",
    "            map50 = results.results_dict.get('metrics/mAP50', 0)\n",
    "            raad_value = results.results_dict.get('raad', 0)\n",
    "            \n",
    "            summary_table.add_data(model_type, split, map50, raad_value, training_time)\n",
    "            \n",
    "            run.finish()\n",
    "    \n",
    "    # Create final summary run\n",
    "    summary_run = wandb.init(project=\"maize_detection_summary\", name=f\"{model_type.split('.')[0]}_summary\")\n",
    "    wandb.log({\"split_comparison\": summary_table})\n",
    "    summary_run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f174c99b-5f1e-46e8-9eb9-5606a77b1caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def analyze_results():\n",
    "    \"\"\"\n",
    "    Analyze and visualize training results across splits and models\n",
    "    \"\"\"\n",
    "    # Initialize wandb\n",
    "    run = wandb.init(project=\"maize_detection_analysis\", name=\"final_analysis\")\n",
    "    \n",
    "    # Load experiment results from wandb API\n",
    "    api = wandb.Api()\n",
    "    \n",
    "    # Get runs from different projects\n",
    "    baseline_runs = api.runs(\"maize_detection_baseline\")\n",
    "    split_runs = api.runs(\"maize_detection_splits\")\n",
    "    \n",
    "    # Extract metrics into pandas dataframes\n",
    "    baseline_df = pd.DataFrame([\n",
    "        {\n",
    "            \"model\": run.config.get(\"model\", \"unknown\"),\n",
    "            \"split\": \"SID01\",  # Baseline only used SID01\n",
    "            \"mAP50\": run.summary.get(\"metrics/mAP50\", 0),\n",
    "            \"raad\": run.summary.get(\"raad\", 0),\n",
    "            \"training_time\": run.summary.get(\"_runtime\", 0) / 60  # minutes\n",
    "        }\n",
    "        for run in baseline_runs\n",
    "    ])\n",
    "    \n",
    "    split_df = pd.DataFrame([\n",
    "        {\n",
    "            \"model\": run.config.get(\"model\", \"unknown\"),\n",
    "            \"split\": run.config.get(\"split\", \"unknown\"),\n",
    "            \"mAP50\": run.summary.get(\"metrics/mAP50\", 0),\n",
    "            \"raad\": run.summary.get(\"raad\", 0),\n",
    "            \"training_time\": run.summary.get(\"_runtime\", 0) / 60  # minutes\n",
    "        }\n",
    "        for run in split_runs\n",
    "    ])\n",
    "    \n",
    "    # Combine dataframes\n",
    "    all_df = pd.concat([baseline_df, split_df])\n",
    "    \n",
    "    # Create visualizations\n",
    "    \n",
    "    # 1. mAP50 vs RAAD scatter plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.scatterplot(data=all_df, x=\"mAP50\", y=\"raad\", hue=\"split\", size=\"model\", sizes=(100, 200))\n",
    "    plt.title(\"mAP50 vs RAAD by Split and Model\")\n",
    "    plt.xlabel(\"mAP50\")\n",
    "    plt.ylabel(\"RAAD (lower is better)\")\n",
    "    plt.savefig(\"map_vs_raad.png\")\n",
    "    wandb.log({\"map_vs_raad\": wandb.Image(\"map_vs_raad.png\")})\n",
    "    \n",
    "    # 2. Model performance by split (bar chart)\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Plot for mAP50\n",
    "    plt.subplot(2, 1, 1)\n",
    "    sns.barplot(data=all_df, x=\"model\", y=\"mAP50\", hue=\"split\")\n",
    "    plt.title(\"mAP50 by Model and Split\")\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Plot for RAAD\n",
    "    plt.subplot(2, 1, 2)\n",
    "    sns.barplot(data=all_df, x=\"model\", y=\"raad\", hue=\"split\")\n",
    "    plt.title(\"RAAD by Model and Split (lower is better)\")\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"model_performance.png\")\n",
    "    wandb.log({\"model_performance\": wandb.Image(\"model_performance.png\")})\n",
    "    \n",
    "    # 3. Create summary table\n",
    "    summary_table = wandb.Table(dataframe=all_df)\n",
    "    wandb.log({\"summary_results\": summary_table})\n",
    "    \n",
    "    # 4. Key findings\n",
    "    best_map_model = all_df.loc[all_df[\"mAP50\"].idxmax()]\n",
    "    best_raad_model = all_df.loc[all_df[\"raad\"].idxmin()]  # Lower RAAD is better\n",
    "    \n",
    "    findings = f\"\"\"\n",
    "    # Key Findings\n",
    "    \n",
    "    ## Best Model by mAP50\n",
    "    - Model: {best_map_model['model']}\n",
    "    - Split: {best_map_model['split']}\n",
    "    - mAP50: {best_map_model['mAP50']:.4f}\n",
    "    - RAAD: {best_map_model['raad']:.4f}\n",
    "    \n",
    "    ## Best Model by RAAD\n",
    "    - Model: {best_raad_model['model']}\n",
    "    - Split: {best_raad_model['split']}\n",
    "    - mAP50: {best_raad_model['mAP50']:.4f}\n",
    "    - RAAD: {best_raad_model['raad']:.4f}\n",
    "    \n",
    "    ## Split Comparisons\n",
    "    - SID01 (Standard Split): Average mAP50 = {all_df[all_df['split'] == 'SID01']['mAP50'].mean():.4f}\n",
    "    - SID02 (Device-specific): Average mAP50 = {all_df[all_df['split'] == 'SID02']['mAP50'].mean():.4f}\n",
    "    - SID03 (K-fold): Average mAP50 = {all_df[all_df['split'].str.contains('SID03')]['mAP50'].mean():.4f}\n",
    "    \n",
    "    ## RAAD vs mAP50\n",
    "    - Correlation between RAAD and mAP50: {all_df['raad'].corr(all_df['mAP50']):.4f}\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(\"findings.md\", \"w\") as f:\n",
    "        f.write(findings)\n",
    "    \n",
    "    wandb.save(\"findings.md\")\n",
    "    \n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b394b5ee-680b-4b34-8925-9ac4b32733e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
